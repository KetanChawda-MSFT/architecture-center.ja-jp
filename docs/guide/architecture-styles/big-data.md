---
title: "ビッグ データ アーキテクチャのスタイル"
description: "Azure でのビッグ データ アーキテクチャのメリット、課題、ベスト プラクティスを説明します"
author: MikeWasson
ms.openlocfilehash: 4e8b58d5fa0f6a441d70e05ec7d6a0e668712563
ms.sourcegitcommit: b0482d49aab0526be386837702e7724c61232c60
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 11/14/2017
---
# <a name="big-data-architecture-style"></a><span data-ttu-id="ce64e-103">ビッグ データ アーキテクチャのスタイル</span><span class="sxs-lookup"><span data-stu-id="ce64e-103">Big data architecture style</span></span>

<span data-ttu-id="ce64e-104">ビッグ データ アーキテクチャは、従来のデータベース システムには多すぎる、または複雑すぎるデータのインジェスト、処理、分析を扱うために設計されています。</span><span class="sxs-lookup"><span data-stu-id="ce64e-104">A big data architecture is designed to handle the ingestion, processing, and analysis of data that is too large or complex for traditional database systems.</span></span>

![](./images/big-data-logical.svg)

 <span data-ttu-id="ce64e-105">ビッグ データ ソリューションには、通常は、次の種類のワークロードが 1 つ以上関係しています。</span><span class="sxs-lookup"><span data-stu-id="ce64e-105">Big data solutions typically involve one or more of the following types of workload:</span></span>

- <span data-ttu-id="ce64e-106">保存されているビッグ データ ソースのバッチ処理。</span><span class="sxs-lookup"><span data-stu-id="ce64e-106">Batch processing of big data sources at rest.</span></span>
- <span data-ttu-id="ce64e-107">動作中のビッグ データのリアルタイム処理。</span><span class="sxs-lookup"><span data-stu-id="ce64e-107">Real-time processing of big data in motion.</span></span>
- <span data-ttu-id="ce64e-108">ビッグ データの対話型探索。</span><span class="sxs-lookup"><span data-stu-id="ce64e-108">Interactive exploration of big data.</span></span>
- <span data-ttu-id="ce64e-109">予測分析と機械学習。</span><span class="sxs-lookup"><span data-stu-id="ce64e-109">Predictive analytics and machine learning.</span></span>

<span data-ttu-id="ce64e-110">大部分のビッグ データ アーキテクチャには、次のコンポーネントの一部またはすべてが含まれています。</span><span class="sxs-lookup"><span data-stu-id="ce64e-110">Most big data architectures include some or all of the following components:</span></span>

- <span data-ttu-id="ce64e-111">**データ ソース**: すべてのビッグ データ ソリューションは、1 つ以上のデータ ソースから始まります。</span><span class="sxs-lookup"><span data-stu-id="ce64e-111">**Data sources**: All big data solutions start with one or more data sources.</span></span> <span data-ttu-id="ce64e-112">たとえば、次のようになります。</span><span class="sxs-lookup"><span data-stu-id="ce64e-112">Examples include:</span></span>

    - <span data-ttu-id="ce64e-113">リレーショナル データベースなど、アプリケーション データ ストア。</span><span class="sxs-lookup"><span data-stu-id="ce64e-113">Application data stores, such as relational databases.</span></span>
    - <span data-ttu-id="ce64e-114">Web サーバー ログ ファイルなど、アプリケーションによって生成された静的ファイル。</span><span class="sxs-lookup"><span data-stu-id="ce64e-114">Static files produced by applications, such as web server log files.</span></span>
    - <span data-ttu-id="ce64e-115">IoT デバイスなど、リアルタイムのデータ ソース。</span><span class="sxs-lookup"><span data-stu-id="ce64e-115">Real-time data sources, such as IoT devices.</span></span>

- <span data-ttu-id="ce64e-116">**データ ストレージ**: バッチ処理操作のためのデータは、通常は、さまざまな形式の大きなファイルを大量に保持できる分散ファイル ストアに保存されます。</span><span class="sxs-lookup"><span data-stu-id="ce64e-116">**Data storage**: Data for batch processing operations is typically stored in a distributed file store that can hold high volumes of large files in various formats.</span></span> <span data-ttu-id="ce64e-117">この種のストアは、*Data Lake* とも呼ばれます。</span><span class="sxs-lookup"><span data-stu-id="ce64e-117">This kind of store is often called a *data lake*.</span></span> <span data-ttu-id="ce64e-118">このストレージを実装するための選択肢としては、Azure Data Lake Store、または Azure Storage 内の BLOB コンテナーなどがあります。</span><span class="sxs-lookup"><span data-stu-id="ce64e-118">Options for implementing this storage include Azure Data Lake Store or blob containers in Azure Storage.</span></span> 

- <span data-ttu-id="ce64e-119">**バッチ処理**: データ セットは非常に大きいため、多くの場合、ビッグ データ ソリューションでは、実行時間の長いバッチ ジョブの使用によってデータ ファイルを処理し、フィルター処理や集計を行うなどして分析用のデータを準備する必要があります。</span><span class="sxs-lookup"><span data-stu-id="ce64e-119">**Batch processing**: Because the data sets are so large, often a big data solution must process data files using long-running batch jobs to filter, aggregate, and otherwise prepare the data for analysis.</span></span> <span data-ttu-id="ce64e-120">通常、これらのジョブには、ソース ファイルの読み取り、ソース ファイルの処理、新しいファイルへの出力の書き込みが含まれます。</span><span class="sxs-lookup"><span data-stu-id="ce64e-120">Usually these jobs involve reading source files, processing them, and writing the output to new files.</span></span> <span data-ttu-id="ce64e-121">選択肢には、Azure Data Lake Analytics での U-SQL ジョブの実行、HDInsight Hadoop クラスターでの Hive、Pig、またはカスタム Map/Reduce ジョブの使用、あるいは HDInsight Spark クラスターでの Java、Scala、または Python プログラムの使用などがあります。</span><span class="sxs-lookup"><span data-stu-id="ce64e-121">Options include running U-SQL jobs in Azure Data Lake Analytics, using Hive, Pig, or custom Map/Reduce jobs in an HDInsight Hadoop cluster, or using Java, Scala, or Python programs in an HDInsight Spark cluster.</span></span>

- <span data-ttu-id="ce64e-122">**リアルタイム メッセージのインジェスト**: ソリューションにリアルタイム ソースが含まれている場合は、アーキテクチャに、ストリーム処理のためにリアルタイム ッセージを取得して保存する方法が含まれている必要があります。</span><span class="sxs-lookup"><span data-stu-id="ce64e-122">**Real-time message ingestion**: If the solution includes real-time sources, the architecture must include a way to capture and store real-time messages for stream processing.</span></span> <span data-ttu-id="ce64e-123">これは、受信メッセージを処理用のフォルダーにドロップするような、単純なデータ ストアにすることもできます。</span><span class="sxs-lookup"><span data-stu-id="ce64e-123">This might be a simple data store, where incoming messages are dropped into a folder for processing.</span></span> <span data-ttu-id="ce64e-124">ただし、多くのソリューションには、メッセージのためのバッファーとして機能し、スケールアウト処理、信頼性の高い配信、その他のメッセージ キューのセマンティクスをサポートするメッセージ インジェスト ストアが必要です。</span><span class="sxs-lookup"><span data-stu-id="ce64e-124">However, many solutions need a message ingestion store to act as a buffer for messages, and to support scale-out processing, reliable delivery, and other message queuing semantics.</span></span> <span data-ttu-id="ce64e-125">選択肢には、Azure Event Hubs、Azure IoT Hubs、Kafka などがあります。</span><span class="sxs-lookup"><span data-stu-id="ce64e-125">Options include Azure Event Hubs, Azure IoT Hubs, and Kafka.</span></span>

- <span data-ttu-id="ce64e-126">**ストリーム処理**: このソリューションでは、リアルタイム メッセージを取得した後、分析用にデータをフィルターしたり、集計したり、その他の準備を行ったりして、それらのメッセージを処理する必要があります。</span><span class="sxs-lookup"><span data-stu-id="ce64e-126">**Stream processing**: After capturing real-time messages, the solution must process them by filtering, aggregating, and otherwise preparing the data for analysis.</span></span> <span data-ttu-id="ce64e-127">処理されたストリーム データは、その後、出力シンクに書き込まれます。</span><span class="sxs-lookup"><span data-stu-id="ce64e-127">The processed stream data is then written to an output sink.</span></span> <span data-ttu-id="ce64e-128">Azure Stream Analytics では、バインドされていないストリームを操作する SQL クエリの絶え間ない実行に基づいて、管理されたストリーム処理サービスが提供されます。</span><span class="sxs-lookup"><span data-stu-id="ce64e-128">Azure Stream Analytics provides a managed stream processing service based on perpetually running SQL queries that operate on unbounded streams.</span></span> <span data-ttu-id="ce64e-129">HDInsight クラスターで、Storm や Spark Streaming など、オープン ソースの Apache ストリーミング テクノロジを使用することもできます。</span><span class="sxs-lookup"><span data-stu-id="ce64e-129">You can also use open source Apache streaming technologies like Storm and Spark Streaming in an HDInsight cluster.</span></span>

- <span data-ttu-id="ce64e-130">**分析データ ストア**: 多くのビッグ データ ソリューションでは、分析用にデータが準備されてから、処理されたデータが提供されます。このデータは分析ツールを使用して照会可能な、構造化された形式になります。</span><span class="sxs-lookup"><span data-stu-id="ce64e-130">**Analytical data store**: Many big data solutions prepare data for analysis and then serve the processed data in a structured format that can be queried using analytical tools.</span></span> <span data-ttu-id="ce64e-131">これらのクエリの処理に使用する分析データ ストアは、従来のほとんどのビジネス インテリジェンス (BI) ソリューションに見られるように、Kimball スタイルのリレーショナル データ ウェアハウスにすることができます。</span><span class="sxs-lookup"><span data-stu-id="ce64e-131">The analytical data store used to serve these queries can be a Kimball-style relational data warehouse, as seen in most traditional business intelligence (BI) solutions.</span></span> <span data-ttu-id="ce64e-132">別の方法としては、HBase などの待機時間の短い NoSQL テクノロジや、分散データ ストア内のデータ ファイル上のメタデータ抽象化を提供する対話型 Hive データベースを通じて、データを利用できます。</span><span class="sxs-lookup"><span data-stu-id="ce64e-132">Alternatively, the data could be presented through a low-latency NoSQL technology such as HBase, or an interactive Hive database that provides a metadata abstraction over data files in the distributed data store.</span></span> <span data-ttu-id="ce64e-133">Azure SQL Data Warehouse では、クラウドベースの大規模なデータ ウェアハウスのための、管理されたサービスが提供されます。</span><span class="sxs-lookup"><span data-stu-id="ce64e-133">Azure SQL Data Warehouse provides a managed service for large-scale, cloud-based data warehousing.</span></span> <span data-ttu-id="ce64e-134">HDInsight では対話型の Hive、HBase、Spark SQL をサポートしており、これらを使用して分析用のデータを処理することもできます。</span><span class="sxs-lookup"><span data-stu-id="ce64e-134">HDInsight supports Interactive Hive, HBase, and Spark SQL, which can also be used to serve data for analysis.</span></span>

- <span data-ttu-id="ce64e-135">**分析とレポート**: ほとんどのビッグ データ ソリューションの目的は、分析とレポートによってデータに関する実用的な情報を提供することにあります。</span><span class="sxs-lookup"><span data-stu-id="ce64e-135">**Analysis and reporting**: The goal of most big data solutions is to provide insights into the data through analysis and reporting.</span></span> <span data-ttu-id="ce64e-136">ユーザーによるデータ分析を支援するために、Azure Analysis Services での多次元 OLAP キューブまたは表形式データ モデルなどのデータ モデリング レイヤーをアーキテクチャに組み込むことができます。</span><span class="sxs-lookup"><span data-stu-id="ce64e-136">To empower users to analyze the data, the architecture may include a data modeling layer, such as a multidimensional OLAP cube or tabular data model in Azure Analysis Services.</span></span> <span data-ttu-id="ce64e-137">Microsoft Power BI または Microsoft Excel 内のモデリング テクノロジおよび視覚化テクノロジを使用して、セルフサービス BI をサポートすることもできます。</span><span class="sxs-lookup"><span data-stu-id="ce64e-137">It might also support self-service BI, using the modeling and visualization technologies in Microsoft Power BI or Microsoft Excel.</span></span> <span data-ttu-id="ce64e-138">分析とレポートは、データ サイエンティストやデータ アナリストによる対話型のデータ探索の形で行うこともできます。</span><span class="sxs-lookup"><span data-stu-id="ce64e-138">Analysis and reporting can also take the form of interactive data exploration by data scientists or data analysts.</span></span> <span data-ttu-id="ce64e-139">これらのシナリオでは、多くの Azure サービスで Jupyter などの分析ノートブックがサポートされており、そのユーザーは Python や R に関する既存のスキルを活用できます。大規模なデータ探索の場合は、Microsoft R Server をスタンドアロンでも、Spark と組み合わせても使用できます。</span><span class="sxs-lookup"><span data-stu-id="ce64e-139">For these scenarios, many Azure services support analytical notebooks, such as Jupyter, enabling these users to leverage their existing skills with Python or R. For large-scale data exploration, you can use Microsoft R Server, either standalone or with Spark.</span></span>

- <span data-ttu-id="ce64e-140">**オーケストレーション**: ほとんどのビッグ データ ソリューションはデータの反復処理操作で構成されており、ワークフロー内でカプセル化されています。この処理操作では、ソース データの変換や複数のソースとシンクとの間でのデータ移動、処理されたデータの分析データ ストアへの読み込み、レポートまたはダッシュボードへのダイレクトな結果のプッシュが行われます。</span><span class="sxs-lookup"><span data-stu-id="ce64e-140">**Orchestration**: Most big data solutions consist of repeated data processing operations, encapsulated in workflows, that transform source data, move data between multiple sources and sinks, load the processed data into an analytical data store, or push the results straight to a report or dashboard.</span></span> <span data-ttu-id="ce64e-141">これらのワークフローを自動化するために、Azure Data Factory や Apache Oozie および Sqoop などのオーケストレーション テクノロジを使用できます。</span><span class="sxs-lookup"><span data-stu-id="ce64e-141">To automate these workflows, you can use an orchestration technology such Azure Data Factory or Apache Oozie and Sqoop.</span></span>

<span data-ttu-id="ce64e-142">Azure には、ビッグ データ アーキテクチャで使用できる数多くのサービスがあります。</span><span class="sxs-lookup"><span data-stu-id="ce64e-142">Azure includes many services that can be used in a big data architecture.</span></span> <span data-ttu-id="ce64e-143">それらは、ほぼ次の 2 つのカテゴリに分類されます。</span><span class="sxs-lookup"><span data-stu-id="ce64e-143">They fall roughly into two categories:</span></span>

- <span data-ttu-id="ce64e-144">Azure Data Lake Store、Azure Data Lake Analytics、Azure Data Warehouse、Azure Stream Analytics、Azure Event Hub、Azure IoT Hub、Azure Data Factory などの、管理されたサービス。</span><span class="sxs-lookup"><span data-stu-id="ce64e-144">Managed services, including Azure Data Lake Store, Azure Data Lake Analytics, Azure Data Warehouse, Azure Stream Analytics, Azure Event Hub, Azure IoT Hub, and Azure Data Factory.</span></span>
- <span data-ttu-id="ce64e-145">HDFS、HBase、Hive、Pig、Spark、Storm、Oozie、Sqoop、Kafka などの、Apache Hadoop プラットフォームを基盤とするオープン ソース テクノロジ。</span><span class="sxs-lookup"><span data-stu-id="ce64e-145">Open source technologies based on the Apache Hadoop platform, including HDFS, HBase, Hive, Pig, Spark, Storm, Oozie, Sqoop, and Kafka.</span></span> <span data-ttu-id="ce64e-146">これらのテクノロジは、Azure 上の Azure HDInsight サービス内で利用できます。</span><span class="sxs-lookup"><span data-stu-id="ce64e-146">These technologies are available on Azure in the Azure HDInsight service.</span></span>

<span data-ttu-id="ce64e-147">これらの選択肢は相互に排他的ではなく、多くのソリューションでは、Azure サービスとオープン ソース テクノロジが組み合わされています。</span><span class="sxs-lookup"><span data-stu-id="ce64e-147">These options are not mutually exclusive, and many solutions combine open source technologies with Azure services.</span></span>

## <a name="when-to-use-this-architecture"></a><span data-ttu-id="ce64e-148">このアーキテクチャを使用する状況</span><span class="sxs-lookup"><span data-stu-id="ce64e-148">When to use this architecture</span></span>

<span data-ttu-id="ce64e-149">次のことが必要な場合は、このアーキテクチャ スタイルの使用を検討してください。</span><span class="sxs-lookup"><span data-stu-id="ce64e-149">Consider this architecture style when you need to:</span></span>

- <span data-ttu-id="ce64e-150">従来のデータベースには多すぎる、大量のデータを保存および処理する。</span><span class="sxs-lookup"><span data-stu-id="ce64e-150">Store and process data in volumes too large for a traditional database.</span></span>
- <span data-ttu-id="ce64e-151">分析とレポートのために非構造化データを変換する。</span><span class="sxs-lookup"><span data-stu-id="ce64e-151">Transform unstructured data for analysis and reporting.</span></span>
- <span data-ttu-id="ce64e-152">リアルタイムで、または短い待機時間で、バインドされていないデータ ストリームを取得、処理、分析する。</span><span class="sxs-lookup"><span data-stu-id="ce64e-152">Capture, process, and analyze unbounded streams of data in real time, or with low latency.</span></span>
- <span data-ttu-id="ce64e-153">Azure Machine Learning または Microsoft Cognitive Services を使用する。</span><span class="sxs-lookup"><span data-stu-id="ce64e-153">Use Azure Machine Learning or Microsoft Cognitive Services.</span></span>

## <a name="benefits"></a><span data-ttu-id="ce64e-154">メリット</span><span class="sxs-lookup"><span data-stu-id="ce64e-154">Benefits</span></span>

- <span data-ttu-id="ce64e-155">**テクノロジの選択**。</span><span class="sxs-lookup"><span data-stu-id="ce64e-155">**Technology choices**.</span></span> <span data-ttu-id="ce64e-156">HDInsight クラスター内で Azure の管理されたサービスと Apache テクノロジを組み合わせて適合させることで、既存のスキルやテクノロジへの投資を有効に活用できます。</span><span class="sxs-lookup"><span data-stu-id="ce64e-156">You can mix and match Azure managed services and Apache technologies in HDInsight clusters, to capitalize on existing skills or technology investments.</span></span>
- <span data-ttu-id="ce64e-157">**並列処理によるパフォーマンス**。</span><span class="sxs-lookup"><span data-stu-id="ce64e-157">**Performance through parallelism**.</span></span> <span data-ttu-id="ce64e-158">ビッグ データ ソリューションでは並列処理の強みを活かして、大量のデータをスケーリングする高パフォーマンスのソリューションを実現できます。</span><span class="sxs-lookup"><span data-stu-id="ce64e-158">Big data solutions take advantage of parallelism, enabling high-performance solutions that scale to large volumes of data.</span></span>
- <span data-ttu-id="ce64e-159">**柔軟なスケール**。</span><span class="sxs-lookup"><span data-stu-id="ce64e-159">**Elastic scale**.</span></span> <span data-ttu-id="ce64e-160">ビッグ データ アーキテクチャ内のすべてのコンポーネントで、スケールアウトのプロビジョニングがサポートされています。このサポートにより、ご自分のソリューションをワークロードの規模に合わせて調整でき、しかも使用した分のリソースにしか料金がかかりません。</span><span class="sxs-lookup"><span data-stu-id="ce64e-160">All of the components in the big data architecture support scale-out provisioning, so that you can adjust your solution to small or large workloads, and pay only for the resources that you use.</span></span>
- <span data-ttu-id="ce64e-161">**既存のソリューションとの相互運用性**。</span><span class="sxs-lookup"><span data-stu-id="ce64e-161">**Interoperability with existing solutions**.</span></span> <span data-ttu-id="ce64e-162">ビッグ データ アーキテクチャのコンポーネントは、IoT 処理および企業向けの BI ソリューションにも使用されており、お客様がすべてのデータ ワークロードにわたる統合されたソリューションを作成できるようにします。</span><span class="sxs-lookup"><span data-stu-id="ce64e-162">The components of the big data architecture are also used for IoT processing and enterprise BI solutions, enabling you to create an integrated solution across data workloads.</span></span>

## <a name="challenges"></a><span data-ttu-id="ce64e-163">課題</span><span class="sxs-lookup"><span data-stu-id="ce64e-163">Challenges</span></span>

- <span data-ttu-id="ce64e-164">**複雑さ**。</span><span class="sxs-lookup"><span data-stu-id="ce64e-164">**Complexity**.</span></span> <span data-ttu-id="ce64e-165">ビッグ データ ソリューションは、多数のコンポーネントで複数のデータ ソースからのデータ インジェストを処理するため、非常に複雑になる可能性があります。</span><span class="sxs-lookup"><span data-stu-id="ce64e-165">Big data solutions can be extremely complex, with numerous components to handle data ingestion from multiple data sources.</span></span> <span data-ttu-id="ce64e-166">ビッグ データ プロセスの構築、テスト、トラブルシューティングは、困難を伴う場合があります。</span><span class="sxs-lookup"><span data-stu-id="ce64e-166">It can be challenging to build, test, and troubleshoot big data processes.</span></span> <span data-ttu-id="ce64e-167">その上、パフォーマンスを最適化するために使用する構成の設定が、大量かつ複数のシステムにわたって必要になる可能性があります。</span><span class="sxs-lookup"><span data-stu-id="ce64e-167">Moreover, there may be a large number of configuration settings across multiple systems that must be used in order to optimize performance.</span></span>
- <span data-ttu-id="ce64e-168">**スキルセット**。</span><span class="sxs-lookup"><span data-stu-id="ce64e-168">**Skillset**.</span></span> <span data-ttu-id="ce64e-169">多くのビッグ データ テクノロジは、非常に専門化されており、より一般的なアプリケーション アーキテクチャではあまり使用されていないフレームワークと言語を使用しています。</span><span class="sxs-lookup"><span data-stu-id="ce64e-169">Many big data technologies are highly specialized, and use frameworks and languages that are not typical of more general application architectures.</span></span> <span data-ttu-id="ce64e-170">一方で、ビッグ データ テクノロジは、確立されたより多くの言語を基に構築された、新しい API を発展させています。</span><span class="sxs-lookup"><span data-stu-id="ce64e-170">On the other hand, big data technologies are evolving new APIs that build on more established languages.</span></span> <span data-ttu-id="ce64e-171">たとえば、Azure Data Lake Analytics での U-SQL 言語は、Transact-SQL と C# の組合せが基盤になっています。</span><span class="sxs-lookup"><span data-stu-id="ce64e-171">For example, the U-SQL language in Azure Data Lake Analytics is based on a combination of Transact-SQL and C#.</span></span> <span data-ttu-id="ce64e-172">同様に、SQL ベースの API を Hive、HBase、Spark で使用できます。</span><span class="sxs-lookup"><span data-stu-id="ce64e-172">Similarly, SQL-based APIs are available for Hive, HBase, and Spark.</span></span>
- <span data-ttu-id="ce64e-173">**テクノロジの成熟度**。</span><span class="sxs-lookup"><span data-stu-id="ce64e-173">**Technology maturity**.</span></span> <span data-ttu-id="ce64e-174">ビッグ データで使用されるテクノロジの多くは、進化しています。</span><span class="sxs-lookup"><span data-stu-id="ce64e-174">Many of the technologies used in big data are evolving.</span></span> <span data-ttu-id="ce64e-175">Hive や Pig などの主要な Hadoop テクノロジが安定しているのに対して、Spark などの新興テクノロジでは、新たなリリースのたびに大幅な変更と改良が採用されます。</span><span class="sxs-lookup"><span data-stu-id="ce64e-175">While core Hadoop technologies such as Hive and Pig have stabilized, emerging technologies such as Spark introduce extensive changes and enhancements with each new release.</span></span> <span data-ttu-id="ce64e-176">Azure Data Lake Analytics や Azure Data Factory などの管理されたサービスは、他の Azure サービスと比べて比較的新しく、時間と共に進化する可能性があります。</span><span class="sxs-lookup"><span data-stu-id="ce64e-176">Managed services such as Azure Data Lake Analytics and Azure Data Factory are relatively young, compared with other Azure services, and will likely evolve over time.</span></span>
- <span data-ttu-id="ce64e-177">**セキュリティ**。</span><span class="sxs-lookup"><span data-stu-id="ce64e-177">**Security**.</span></span> <span data-ttu-id="ce64e-178">ビッグ データ ソリューションは、通常は、一元化された Data Lake へのすべての静的データの保存に頼っています。</span><span class="sxs-lookup"><span data-stu-id="ce64e-178">Big data solutions usually rely on storing all static data in a centralized data lake.</span></span> <span data-ttu-id="ce64e-179">このデータへのアクセスを保護することが課題となる可能性があります。特に、データを複数のアプリケーションとプラットフォームでインジェストして使用される必要がある場合には、それが顕著になります。</span><span class="sxs-lookup"><span data-stu-id="ce64e-179">Securing access to this data can be challenging, especially when the data must be ingested and consumed by multiple applications and platforms.</span></span>

## <a name="best-practices"></a><span data-ttu-id="ce64e-180">ベスト プラクティス</span><span class="sxs-lookup"><span data-stu-id="ce64e-180">Best practices</span></span>

- <span data-ttu-id="ce64e-181">**並行処理の活用**。</span><span class="sxs-lookup"><span data-stu-id="ce64e-181">**Leverage parallelism**.</span></span> <span data-ttu-id="ce64e-182">大部分のビッグ データ処理テクノロジでは、複数の処理単位にわたり、ワークロードが分散されます。</span><span class="sxs-lookup"><span data-stu-id="ce64e-182">Most big data processing technologies distribute the workload across multiple processing units.</span></span> <span data-ttu-id="ce64e-183">このためには、分割可能な形式で静的なデータ ファイルを作成し保存することが必要です。</span><span class="sxs-lookup"><span data-stu-id="ce64e-183">This requires that static data files are created and stored in a splittable format.</span></span> <span data-ttu-id="ce64e-184">HDFS などの分散ファイル システムでは、読み取りと書き込みのパフォーマンスを最適化できます。実際の処理は、複数のクラスター ノードで並列的に実行されることで、全体的なジョブの時間は短縮されます。</span><span class="sxs-lookup"><span data-stu-id="ce64e-184">Distributed file systems such as HDFS can optimize read and write performance, and the actual processing is performed by multiple cluster nodes in parallel, which reduces overall job times.</span></span>

- <span data-ttu-id="ce64e-185">**データのパーティション分割**。</span><span class="sxs-lookup"><span data-stu-id="ce64e-185">**Partition data**.</span></span> <span data-ttu-id="ce64e-186">バッチ処理は、通常は、週次や月次など、定期的なスケジュールで行われます。</span><span class="sxs-lookup"><span data-stu-id="ce64e-186">Batch processing usually happens on a recurring schedule &mdash; for example, weekly or monthly.</span></span> <span data-ttu-id="ce64e-187">処理スケジュールに一致するテンポラルの期間に基づいて、データ ファイルや、テーブルなどのデータ構造をパーティション分割します。</span><span class="sxs-lookup"><span data-stu-id="ce64e-187">Partition data files, and data structures such as tables, based on temporal periods that match the processing schedule.</span></span> <span data-ttu-id="ce64e-188">これにより、データ インジェストやジョブ スケジューリングが簡略化され、障害のトラブルシューティングが簡単になります。</span><span class="sxs-lookup"><span data-stu-id="ce64e-188">That simplifies data ingestion and job scheduling, and makes it easier to troubleshoot failures.</span></span> <span data-ttu-id="ce64e-189">また、Hive、U-SQL、または SQL クエリで使用されるテーブルをパーティション分割すると、クエリ パフォーマンスが大幅に向上します。</span><span class="sxs-lookup"><span data-stu-id="ce64e-189">Also, partitioning tables that are used in Hive, U-SQL, or SQL queries can significantly improve query performance.</span></span>

- <span data-ttu-id="ce64e-190">**読み取り時のスキーマのセマンティクスの適用**。</span><span class="sxs-lookup"><span data-stu-id="ce64e-190">**Apply schema-on-read semantics**.</span></span> <span data-ttu-id="ce64e-191">Data Lake を使用すると、構造化、半構造化、非構造化のいずれであるかに関係なく、複数の形式のファイル用にストレージを結合できます。</span><span class="sxs-lookup"><span data-stu-id="ce64e-191">Using a data lake lets you to combine storage for files in multiple formats, whether structured, semi-structured, or unstructured.</span></span> <span data-ttu-id="ce64e-192">データ保存時ではなくデータ処理時にデータにスキーマが投影される、*読み取り時のスキーマ*のセマンティクスを使用します。</span><span class="sxs-lookup"><span data-stu-id="ce64e-192">Use *schema-on-read* semantics, which project a schema onto the data when the data is processing, not when the data is stored.</span></span> <span data-ttu-id="ce64e-193">このことで、ソリューションに柔軟性が組み込まれ、データ検証と型チェックによって起こる、データ インジェスト中のボトルネックを防ぐことができます。</span><span class="sxs-lookup"><span data-stu-id="ce64e-193">This builds flexibility into the solution, and prevents bottlenecks during data ingestion caused by data validation and type checking.</span></span>

- <span data-ttu-id="ce64e-194">**適所でのデータの処理**。</span><span class="sxs-lookup"><span data-stu-id="ce64e-194">**Process data in-place**.</span></span> <span data-ttu-id="ce64e-195">従来の BI ソリューションでは、多くの場合、データ ウェアハウスにデータを移動するのに、抽出、変換、読み込み (ETL) のプロセスが使用されます。</span><span class="sxs-lookup"><span data-stu-id="ce64e-195">Traditional BI solutions often use an extract, transform, and load (ETL) process to move data into a data warehouse.</span></span> <span data-ttu-id="ce64e-196">大量のデータとさまざまな種類の形式が使用されるビッグ データ ソリューションでは、一般に、変換、抽出、読み込み (TEL) など、ETL が変化したものが使用されます。</span><span class="sxs-lookup"><span data-stu-id="ce64e-196">With larger volumes data, and a greater variety of formats, big data solutions generally use variations of ETL, such as transform, extract, and load (TEL).</span></span> <span data-ttu-id="ce64e-197">この方法では、データは分散データ ストア内で処理され、必要な構造に変換されてから分析データ ストアに移動されます。</span><span class="sxs-lookup"><span data-stu-id="ce64e-197">With this approach, the data is processed within the distributed data store, transforming it to the required structure, before moving the transformed data into an analytical data store.</span></span>

- <span data-ttu-id="ce64e-198">**使用率と時間的なコストの均衡化**。</span><span class="sxs-lookup"><span data-stu-id="ce64e-198">**Balance utilization and time costs**.</span></span> <span data-ttu-id="ce64e-199">バッチ処理ジョブの場合は、コンピューティング ノードの単位あたりのコストと、それらのノードを使用してジョブを完了する 1 分あたりのコストという、2 つの要因を考慮することが重要です。</span><span class="sxs-lookup"><span data-stu-id="ce64e-199">For batch processing jobs, it's important to consider two factors: The per-unit cost of the compute nodes, and the per-minute cost of using those nodes to complete the job.</span></span> <span data-ttu-id="ce64e-200">たとえば、1 つのバッチ ジョブが、4 つのクラスター ノードで 8 時間かけて行われるとします。</span><span class="sxs-lookup"><span data-stu-id="ce64e-200">For example, a batch job may take eight hours with four cluster nodes.</span></span> <span data-ttu-id="ce64e-201">ただし、そのジョブでは最初の 2 時間のみ 4 つすべてのノードが使用され、それ以降は、2 つのノードのみが必要になるということがわかったとします。</span><span class="sxs-lookup"><span data-stu-id="ce64e-201">However, it might turn out that the job uses all four nodes only during the first two hours, and after that, only two nodes are required.</span></span> <span data-ttu-id="ce64e-202">その場合は、すべてのジョブを 2 つのノードで実行すると、ジョブの合計時間は長くなりますが倍にはならないため、総コストは低くなります。</span><span class="sxs-lookup"><span data-stu-id="ce64e-202">In that case, running the entire job on two nodes would increase the total job time, but would not double it, so the total cost would be less.</span></span> <span data-ttu-id="ce64e-203">一部のビジネス シナリオでは、使用率の低いクラスター リソースの使用にかかるコストが高くつくよりも、処理時間が長くなるほうが好まれる場合もあります。</span><span class="sxs-lookup"><span data-stu-id="ce64e-203">In some business scenarios, a longer processing time may be preferable to the higher cost of using under-utilized cluster resources.</span></span>

- <span data-ttu-id="ce64e-204">**クラスター リソースの分離**。</span><span class="sxs-lookup"><span data-stu-id="ce64e-204">**Separate cluster resources**.</span></span> <span data-ttu-id="ce64e-205">HDInsight クラスターをデプロイするときは、通常は、ワークロードの種類ごとに別個のクラスター リソースをプロビジョニングしてパフォーマンスを向上させます。</span><span class="sxs-lookup"><span data-stu-id="ce64e-205">When deploying HDInsight clusters, you will normally achieve better performance by provisioning separate cluster resources for each type of workload.</span></span> <span data-ttu-id="ce64e-206">たとえば、Spark クラスターには Hive が含まれますが、Hive と Spark の両方で大規模な処理を実行する必要がある場合は、Spark および Hadoop 専用のクラスターを別々にデプロイすることを検討する必要があります。</span><span class="sxs-lookup"><span data-stu-id="ce64e-206">For example, although Spark clusters include Hive, if you need to perform extensive processing with both Hive and Spark, you should consider deploying separate dedicated Spark and Hadoop clusters.</span></span> <span data-ttu-id="ce64e-207">同様に、待機時間の短いストリーム処理に HBase と Storm を、バッチ処理に Hive を使用している場合は、Storm、HBase、Hadoop のために別個のクラスターを使用することを検討してください。</span><span class="sxs-lookup"><span data-stu-id="ce64e-207">Similarly, if you are using HBase and Storm for low latency stream processing and Hive for batch processing, consider separate clusters for Storm, HBase, and Hadoop.</span></span>

- <span data-ttu-id="ce64e-208">**データ インジェストの調整**。</span><span class="sxs-lookup"><span data-stu-id="ce64e-208">**Orchestrate data ingestion**.</span></span> <span data-ttu-id="ce64e-209">場合によっては、既存のビジネス アプリケーションが、バッチ処理のためのデータ ファイルを Azure Storage Blob コンテナーに直接書き込むことができ、そこで、そのデータ ファイルを HDInsight または Azure Data Lake Analytics で使用できます。</span><span class="sxs-lookup"><span data-stu-id="ce64e-209">In some cases, existing business applications may write data files for batch processing directly into Azure storage blob containers, where they can be consumed by HDInsight or Azure Data Lake Analytics.</span></span> <span data-ttu-id="ce64e-210">ただし、多くの場合、オンプレミスまたは外部のデータ ソースから Data Lake へのデータのインジェストを調整する必要があります。</span><span class="sxs-lookup"><span data-stu-id="ce64e-210">However, you will often need to orchestrate the ingestion of data from on-premises or external data sources into the data lake.</span></span> <span data-ttu-id="ce64e-211">予測可能な一元的に管理できる方法でこれを実現するには、Azure Data Factory や Oozie でサポートされているようなオーケストレーション ワークフローまたはパイプラインを使用します。</span><span class="sxs-lookup"><span data-stu-id="ce64e-211">Use an orchestration workflow or pipeline, such as those supported by Azure Data Factory or Oozie, to achieve this in a predictable and centrally manageable fashion.</span></span>

- <span data-ttu-id="ce64e-212">**機密性の高いデータの早期の除外**。</span><span class="sxs-lookup"><span data-stu-id="ce64e-212">**Scrub sensitive data early**.</span></span> <span data-ttu-id="ce64e-213">データ インジェスト ワークフローでは、プロセスの早い段階で機密性の高いデータを除外して、Data Lake に保存しないようにする必要があります。</span><span class="sxs-lookup"><span data-stu-id="ce64e-213">The data ingestion workflow should scrub sensitive data early in the process, to avoid storing it in the data lake.</span></span>
