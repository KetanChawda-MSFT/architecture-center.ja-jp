---
title: ディープ ラーニング モデル用のバッチ スコアリング
titleSuffix: Azure Reference Architectures
description: この参照アーキテクチャでは、Azure Batch AI を使用してニューラル スタイルの転送を動画に適用する方法を示します。
author: jiata
ms.date: 10/02/2018
ms.topic: reference-architecture
ms.service: architecture-center
ms.subservice: reference-architecture
ms.custom: azcat-ai
ms.openlocfilehash: 27975b42179e87f4520186778610159943a93090
ms.sourcegitcommit: 40f3561cc94f721eca50d33f2d75dc974cb6f92b
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 01/29/2019
ms.locfileid: "55147248"
---
# <a name="batch-scoring-on-azure-for-deep-learning-models"></a><span data-ttu-id="97c9b-103">ディープ ラーニング モデル用の Azure でのバッチ スコアリング</span><span class="sxs-lookup"><span data-stu-id="97c9b-103">Batch scoring on Azure for deep learning models</span></span>

<span data-ttu-id="97c9b-104">この参照アーキテクチャでは、Azure Batch AI を使用してニューラル スタイルの転送を動画に適用する方法を示します。</span><span class="sxs-lookup"><span data-stu-id="97c9b-104">This reference architecture shows how to apply neural style transfer to a video, using Azure Batch AI.</span></span> <span data-ttu-id="97c9b-105">"*スタイルの転送*" とは、別の画像のスタイルに既存の画像を組み込むディープ ラーニングの手法です。</span><span class="sxs-lookup"><span data-stu-id="97c9b-105">*Style transfer* is a deep learning technique that composes an existing image in the style of another image.</span></span> <span data-ttu-id="97c9b-106">このアーキテクチャは、ディープ ラーニングでバッチ スコアリングを使用する任意のシナリオに一般化することができます。</span><span class="sxs-lookup"><span data-stu-id="97c9b-106">This architecture can be generalized for any scenario that uses batch scoring with deep learning.</span></span> <span data-ttu-id="97c9b-107">[**このソリューションをデプロイします**](#deploy-the-solution)。</span><span class="sxs-lookup"><span data-stu-id="97c9b-107">[**Deploy this solution**](#deploy-the-solution).</span></span>

![Azure Batch AI を使用したディープ ラーニング モデルのアーキテクチャ ダイアグラム](./_images/batch-ai-deep-learning.png)

<span data-ttu-id="97c9b-109">**シナリオ**:あるメディア組織は、動画のスタイルを特定の絵画のように変更したいと考えています。</span><span class="sxs-lookup"><span data-stu-id="97c9b-109">**Scenario**: A media organization has a video whose style they want to change to look like a specific painting.</span></span> <span data-ttu-id="97c9b-110">組織は、適切なタイミングで自動的に動画のすべてのフレームにこのスタイルを適用できることを望んでいます。</span><span class="sxs-lookup"><span data-stu-id="97c9b-110">The organization wants to be able to apply this style to all frames of the video in a timely manner and in an automated fashion.</span></span> <span data-ttu-id="97c9b-111">ニューラル スタイル転送アルゴリズムの背景について詳しくは、「[Image Style Transfer Using Convolutional Neural Networks][image-style-transfer]」(畳み込みニューラル ネットワークを使用した画像スタイルの転送) (PDF) をご覧ください。</span><span class="sxs-lookup"><span data-stu-id="97c9b-111">For more background about neural style transfer algorithms, see [Image Style Transfer Using Convolutional Neural Networks][image-style-transfer] (PDF).</span></span>

| <span data-ttu-id="97c9b-112">スタイル画像:</span><span class="sxs-lookup"><span data-stu-id="97c9b-112">Style image:</span></span> | <span data-ttu-id="97c9b-113">入力/コンテンツ動画:</span><span class="sxs-lookup"><span data-stu-id="97c9b-113">Input/content video:</span></span> | <span data-ttu-id="97c9b-114">出力動画:</span><span class="sxs-lookup"><span data-stu-id="97c9b-114">Output video:</span></span> |
|--------|--------|---------|
| <img src="https://happypathspublic.blob.core.windows.net/assets/batch_scoring_for_dl/style_image.jpg" width="300"> | <span data-ttu-id="97c9b-115">[<img src="https://happypathspublic.blob.core.windows.net/assets/batch_scoring_for_dl/input_video_image_0.jpg" width="300" height="300">](https://happypathspublic.blob.core.windows.net/assets/batch_scoring_for_dl/input_video.mp4 "入力動画") *クリックすると動画が表示されます*</span><span class="sxs-lookup"><span data-stu-id="97c9b-115">[<img src="https://happypathspublic.blob.core.windows.net/assets/batch_scoring_for_dl/input_video_image_0.jpg" width="300" height="300">](https://happypathspublic.blob.core.windows.net/assets/batch_scoring_for_dl/input_video.mp4 "Input Video") *click to view video*</span></span> | <span data-ttu-id="97c9b-116">[<img src="https://happypathspublic.blob.core.windows.net/assets/batch_scoring_for_dl/output_video_image_0.jpg" width="300" height="300">](https://happypathspublic.blob.core.windows.net/assets/batch_scoring_for_dl/output_video.mp4 "出力動画") *クリックすると動画が表示されます*</span><span class="sxs-lookup"><span data-stu-id="97c9b-116">[<img src="https://happypathspublic.blob.core.windows.net/assets/batch_scoring_for_dl/output_video_image_0.jpg" width="300" height="300">](https://happypathspublic.blob.core.windows.net/assets/batch_scoring_for_dl/output_video.mp4 "Output Video") *click to view video*</span></span> |

<span data-ttu-id="97c9b-117">この参照アーキテクチャは、Azure Storage に新しいメディアが存在することによってトリガーされるワークロード用に設計されています。</span><span class="sxs-lookup"><span data-stu-id="97c9b-117">This reference architecture is designed for workloads that are triggered by the presence of new media in Azure storage.</span></span> <span data-ttu-id="97c9b-118">処理には次の手順が含まれます。</span><span class="sxs-lookup"><span data-stu-id="97c9b-118">Processing involves the following steps:</span></span>

1. <span data-ttu-id="97c9b-119">選択したスタイル画像 (ゴッホの絵など) とスタイル転送スクリプトを、Blob Storage にアップロードします。</span><span class="sxs-lookup"><span data-stu-id="97c9b-119">Upload a selected style image (like a Van Gogh painting) and a style transfer script to Blob Storage.</span></span>
1. <span data-ttu-id="97c9b-120">処理を開始する準備ができている自動スケール Batch AI クラスターを作成します。</span><span class="sxs-lookup"><span data-stu-id="97c9b-120">Create an autoscaling Batch AI cluster that is ready to start taking work.</span></span>
1. <span data-ttu-id="97c9b-121">動画ファイルを個々のフレームに分割し、それらのフレームを Blob Storage にアップロードします。</span><span class="sxs-lookup"><span data-stu-id="97c9b-121">Split the video file into individual frames and upload those frames into Blob Storage.</span></span>
1. <span data-ttu-id="97c9b-122">すべてのフレームがアップロードされたら、トリガー ファイルを Blob Storage にアップロードします。</span><span class="sxs-lookup"><span data-stu-id="97c9b-122">Once all frames are uploaded, upload a trigger file to Blob Storage.</span></span>
1. <span data-ttu-id="97c9b-123">このファイルは、Azure Container Instances 内で実行されるコンテナーを作成するロジック アプリをトリガーします。</span><span class="sxs-lookup"><span data-stu-id="97c9b-123">This file triggers a Logic App that creates a container running in Azure Container Instances.</span></span>
1. <span data-ttu-id="97c9b-124">コンテナーで、Batch AI ジョブを作成するスクリプトが実行されます。</span><span class="sxs-lookup"><span data-stu-id="97c9b-124">The container runs a script that creates the Batch AI jobs.</span></span> <span data-ttu-id="97c9b-125">各ジョブで、Batch AI クラスターのノード間に並列にニューラル スタイル転送が適用されます。</span><span class="sxs-lookup"><span data-stu-id="97c9b-125">Each job applies the neural style transfer in parallel across the nodes of the Batch AI cluster.</span></span>
1. <span data-ttu-id="97c9b-126">イメージが生成されると、Blob Storage に保存されます。</span><span class="sxs-lookup"><span data-stu-id="97c9b-126">Once the images are generated, they are saved back to Blob Storage.</span></span>
1. <span data-ttu-id="97c9b-127">生成されたフレームをダウンロードして、画像を動画に合成します。</span><span class="sxs-lookup"><span data-stu-id="97c9b-127">Download the generated frames, and stitch back the images into a video.</span></span>

## <a name="architecture"></a><span data-ttu-id="97c9b-128">アーキテクチャ</span><span class="sxs-lookup"><span data-stu-id="97c9b-128">Architecture</span></span>

<span data-ttu-id="97c9b-129">このアーキテクチャは、次のコンポーネントで構成されます。</span><span class="sxs-lookup"><span data-stu-id="97c9b-129">This architecture consists of the following components.</span></span>

### <a name="compute"></a><span data-ttu-id="97c9b-130">Compute</span><span class="sxs-lookup"><span data-stu-id="97c9b-130">Compute</span></span>

<span data-ttu-id="97c9b-131">**[Azure Batch AI][batch-ai]** は、ニューラル スタイル転送アルゴリズムを実行するために使用されます。</span><span class="sxs-lookup"><span data-stu-id="97c9b-131">**[Azure Batch AI][batch-ai]** is used to run the neural style transfer algorithm.</span></span> <span data-ttu-id="97c9b-132">Batch AI は、GPU 対応の VM でディープ ラーニング フレームワーク用にあらかじめ構成されているコンテナー化された環境を提供することにより、ディープ ラーニング ワークロードをサポートします。</span><span class="sxs-lookup"><span data-stu-id="97c9b-132">Batch AI supports deep learning workloads by providing containerized environments that are pre-configured for deep learning frameworks, on GPU-enabled VMs.</span></span> <span data-ttu-id="97c9b-133">Batch AI は、BLOB ストレージにコンピューティング クラスターを接続することもできます。</span><span class="sxs-lookup"><span data-stu-id="97c9b-133">Batch AI can also connect the compute cluster to Blob storage.</span></span>

> [!NOTE]
> <span data-ttu-id="97c9b-134">Azure Batch AI サービスは 2019 年 3 月に終了する予定であり、このサービスの大規模トレーニングとスコアリングの機能は現在、[Azure Machine Learning Service][amls] において利用可能になっています。</span><span class="sxs-lookup"><span data-stu-id="97c9b-134">The Azure Batch AI service is retiring March 2019, and its at-scale training and scoring capabilities are now available in [Azure Machine Learning Service][amls].</span></span> <span data-ttu-id="97c9b-135">この参照アーキテクチャは近日中に Machine Learning を使用するように改定されます。Machine Learning では、[Azure Machine Learning コンピューティング][aml-compute]という、機械学習モデルのトレーニング、デプロイ、およびスコアリングのためのマネージド コンピューティング先を提供します。</span><span class="sxs-lookup"><span data-stu-id="97c9b-135">This reference architecture will be updated soon to use Machine Learning, which offers a managed compute target called [Azure Machine Learning Compute][aml-compute] for training, deploying, and scoring machine learning models.</span></span>

### <a name="storage"></a><span data-ttu-id="97c9b-136">Storage</span><span class="sxs-lookup"><span data-stu-id="97c9b-136">Storage</span></span>

<span data-ttu-id="97c9b-137">**[BLOB ストレージ][blob-storage]** は、すべての画像 (入力画像、スタイル画像、出力画像) および Batch AI から生成されるすべてのログを格納するために使用されます。</span><span class="sxs-lookup"><span data-stu-id="97c9b-137">**[Blob storage][blob-storage]** is used to store all images (input images, style images, and output images) as well as all logs produced from Batch AI.</span></span> <span data-ttu-id="97c9b-138">BLOB ストレージは、BLOB ストレージでサポートされるオープン ソースの仮想ファイル システムである [blobfuse][blobfuse] を使用して、Batch AI と統合されます。</span><span class="sxs-lookup"><span data-stu-id="97c9b-138">Blob storage integrates with Batch AI via [blobfuse][blobfuse], an open-source virtual filesystem that is backed by Blob storage.</span></span> <span data-ttu-id="97c9b-139">BLOB ストレージは、このワークロードに必要なパフォーマンスに対してコスト効率も非常に優れています。</span><span class="sxs-lookup"><span data-stu-id="97c9b-139">Blob storage is also very cost-effective for the performance that this workload requires.</span></span>

### <a name="trigger--scheduling"></a><span data-ttu-id="97c9b-140">トリガー/スケジュール</span><span class="sxs-lookup"><span data-stu-id="97c9b-140">Trigger / scheduling</span></span>

<span data-ttu-id="97c9b-141">**[Azure Logic Apps][logic-apps]** は、ワークフローをトリガーするために使用されます。</span><span class="sxs-lookup"><span data-stu-id="97c9b-141">**[Azure Logic Apps][logic-apps]** is used to trigger the workflow.</span></span> <span data-ttu-id="97c9b-142">Logic Apps は、コンテナーに BLOB が追加されたことを検出すると、Batch AI プロセスをトリガーします。</span><span class="sxs-lookup"><span data-stu-id="97c9b-142">When the Logic App detects that a blob has been added to the container, it triggers the Batch AI process.</span></span> <span data-ttu-id="97c9b-143">Logic Apps は、BLOB ストレージに対する変更を検出する簡単な方法であり、トリガーを変更するための簡単なプロセスを備えているため、この参照アーキテクチャに非常に適しています。</span><span class="sxs-lookup"><span data-stu-id="97c9b-143">Logic Apps is a good fit for this reference architecture because it's an easy way to detect changes to blob storage and provides an easy process for changing the trigger.</span></span>

<span data-ttu-id="97c9b-144">**[Azure Container Instances][container-instances]** は、Batch AI ジョブを作成する Python スクリプトを実行するために使用されます。</span><span class="sxs-lookup"><span data-stu-id="97c9b-144">**[Azure Container Instances][container-instances]** is used to run the Python scripts that create the Batch AI jobs.</span></span> <span data-ttu-id="97c9b-145">Docker コンテナー内でこれらのスクリプトを実行することは、オンデマンドでスクリプトを実行する便利な方法です。</span><span class="sxs-lookup"><span data-stu-id="97c9b-145">Running these scripts inside a Docker container is a convenient way to run them on demand.</span></span> <span data-ttu-id="97c9b-146">このアーキテクチャでは、Container Instances 用の構築済みのロジック アプリ コネクタがあるため、Container Instances を使用します。これにより、ロジック アプリは Batch AI ジョブをトリガーできます。</span><span class="sxs-lookup"><span data-stu-id="97c9b-146">For this architecture, we use Container Instances because there is a pre-built Logic App connector for it, which allows the Logic App to trigger the Batch AI job.</span></span> <span data-ttu-id="97c9b-147">Container Instances は、ステートレス プロセスを迅速に開始できます。</span><span class="sxs-lookup"><span data-stu-id="97c9b-147">Container Instances can spin up stateless processes quickly.</span></span>

<span data-ttu-id="97c9b-148">**[DockerHub][dockerhub]** は、Container Instances がジョブ作成プロセスの実行に使用する Docker イメージを格納するために使用されます。</span><span class="sxs-lookup"><span data-stu-id="97c9b-148">**[DockerHub][dockerhub]** is used to store the Docker image that Container Instances uses to execute the job creation process.</span></span> <span data-ttu-id="97c9b-149">DockerHub は、使いやすく、Docker ユーザーに対する既定のイメージ リポジトリであるため、このアーキテクチャに選択されました。</span><span class="sxs-lookup"><span data-stu-id="97c9b-149">DockerHub was chosen for this architecture because it's easy to use and is the default image repository for Docker users.</span></span> <span data-ttu-id="97c9b-150">[Azure Container Registry][container-registry] を使用することもできます。</span><span class="sxs-lookup"><span data-stu-id="97c9b-150">[Azure Container Registry][container-registry] can also be used.</span></span>

### <a name="data-preparation"></a><span data-ttu-id="97c9b-151">データの準備</span><span class="sxs-lookup"><span data-stu-id="97c9b-151">Data preparation</span></span>

<span data-ttu-id="97c9b-152">この参照アーキテクチャでは、木の中にいるオランウータンの動画映像を使用します。</span><span class="sxs-lookup"><span data-stu-id="97c9b-152">This reference architecture uses video footage of an orangutan in a tree.</span></span> <span data-ttu-id="97c9b-153">[こちら][source-video]から映像をダウンロードし、次の手順に従ってワークフロー用に処理できます。</span><span class="sxs-lookup"><span data-stu-id="97c9b-153">You can download the footage from [here][source-video] and process it for the workflow by following these steps:</span></span>

1. <span data-ttu-id="97c9b-154">[AzCopy][azcopy] を使用して、パブリック BLOB から動画をダウンロードします。</span><span class="sxs-lookup"><span data-stu-id="97c9b-154">Use [AzCopy][azcopy] to download the video from the public blob.</span></span>
2. <span data-ttu-id="97c9b-155">[FFmpeg][ffmpeg] を使用してオーディオ ファイルを抽出し、後で出力動画にオーディオ ファイルを合成できるようにします。</span><span class="sxs-lookup"><span data-stu-id="97c9b-155">Use [FFmpeg][ffmpeg] to extract the audio file, so that the audio file can be stitched back into the output video later.</span></span>
3. <span data-ttu-id="97c9b-156">FFmpeg を使用して、動画を個々のフレームに分割します。</span><span class="sxs-lookup"><span data-stu-id="97c9b-156">Use FFmpeg to break the video into individual frames.</span></span> <span data-ttu-id="97c9b-157">フレームは、並列で個別に処理されます。</span><span class="sxs-lookup"><span data-stu-id="97c9b-157">The frames will be processed independently, in parallel.</span></span>
4. <span data-ttu-id="97c9b-158">AzCopy を使用して、個々のフレームを BLOB コンテナーにコピーします。</span><span class="sxs-lookup"><span data-stu-id="97c9b-158">Use AzCopy to copy the individual frames into your blob container.</span></span>

<span data-ttu-id="97c9b-159">この段階で、動画映像はニューラル スタイル転送に使用できる形式になっています。</span><span class="sxs-lookup"><span data-stu-id="97c9b-159">At this stage, the video footage is in a form that can be used for neural style transfer.</span></span>

## <a name="performance-considerations"></a><span data-ttu-id="97c9b-160">パフォーマンスに関する考慮事項</span><span class="sxs-lookup"><span data-stu-id="97c9b-160">Performance considerations</span></span>

### <a name="gpu-vs-cpu"></a><span data-ttu-id="97c9b-161">GPU と CPU</span><span class="sxs-lookup"><span data-stu-id="97c9b-161">GPU vs CPU</span></span>

<span data-ttu-id="97c9b-162">ディープ ラーニング ワークロードでは、同等のパフォーマンスを得るためには非常に大規模な CPU クラスターが必要になるため、一般に、CPU より GPU の方がかなり優れています。</span><span class="sxs-lookup"><span data-stu-id="97c9b-162">For deep learning workloads, GPUs will generally out-perform CPUs by a considerable amount, to the extent that a sizeable cluster of CPUs is usually needed to get comparable performance.</span></span> <span data-ttu-id="97c9b-163">このアーキテクチャでは CPU のみを使用することもできますが、GPU の方が優れたコスト/パフォーマンス プロファイルを提供します。</span><span class="sxs-lookup"><span data-stu-id="97c9b-163">While it's an option to use only CPUs in this architecture, GPUs will provide a much better cost/performance profile.</span></span> <span data-ttu-id="97c9b-164">GPU 最適化 VM の最新の [NCv3 シリーズ]vm-sizes-gpu を使用することをお勧めします。</span><span class="sxs-lookup"><span data-stu-id="97c9b-164">We recommend using the latest [NCv3 series]vm-sizes-gpu of GPU optimized VMs.</span></span>

<span data-ttu-id="97c9b-165">すべてのリージョンで、GPU は既定では有効になっていません。</span><span class="sxs-lookup"><span data-stu-id="97c9b-165">GPUs are not enabled by default in all regions.</span></span> <span data-ttu-id="97c9b-166">GPU が有効になっているリージョンを選択してください。</span><span class="sxs-lookup"><span data-stu-id="97c9b-166">Make sure to select a region with GPUs enabled.</span></span> <span data-ttu-id="97c9b-167">さらに、サブスクリプションの既定のクォータでは、GPU 最適化 VM のコア数は 0 です。</span><span class="sxs-lookup"><span data-stu-id="97c9b-167">In addition, subscriptions have a default quota of zero cores for GPU-optimized VMs.</span></span> <span data-ttu-id="97c9b-168">サポート要求を開くことで、このクォータを増やすことができます。</span><span class="sxs-lookup"><span data-stu-id="97c9b-168">You can raise this quota by opening a support request.</span></span> <span data-ttu-id="97c9b-169">ワークロードを実行するための十分なクォータがサブスクリプションにあることを確認してください。</span><span class="sxs-lookup"><span data-stu-id="97c9b-169">Make sure that your subscription has enough quota to run your workload.</span></span>

### <a name="parallelizing-across-vms-vs-cores"></a><span data-ttu-id="97c9b-170">VM とコアの間の並列化</span><span class="sxs-lookup"><span data-stu-id="97c9b-170">Parallelizing across VMs vs cores</span></span>

<span data-ttu-id="97c9b-171">スタイル転送プロセスをバッチ ジョブとして実行するとき、主に GPU 上で実行されるジョブは、VM 間で並列化する必要があります。</span><span class="sxs-lookup"><span data-stu-id="97c9b-171">When running a style transfer process as a batch job, the jobs that run primarily on GPUs will have to be parallelized across VMs.</span></span> <span data-ttu-id="97c9b-172">2 つの方法が可能であり、単一の GPU を備えた VM を使用して大規模なクラスターを作成するか、または多くの GPU を備えた VM を使用して小規模なクラスターを作成することができます。</span><span class="sxs-lookup"><span data-stu-id="97c9b-172">Two approaches are possible: You can create a larger cluster using VMs that have a single GPU, or create a smaller cluster using VMs with many GPUs.</span></span>

<span data-ttu-id="97c9b-173">このワークロードでは、これら 2 つのオプションのパフォーマンスは同等です。</span><span class="sxs-lookup"><span data-stu-id="97c9b-173">For this workload, these two options will have comparable performance.</span></span> <span data-ttu-id="97c9b-174">VM あたりの GPU が多い少数の VM を使用すると、データ移動を削減するのに役立ちます。</span><span class="sxs-lookup"><span data-stu-id="97c9b-174">Using fewer VMs with more GPUs per VM can help to reduce data movement.</span></span> <span data-ttu-id="97c9b-175">ただし、このワークロードではジョブごとのデータ量がそれほど多くないので、BLOB ストレージによって大きく制限されることはありません。</span><span class="sxs-lookup"><span data-stu-id="97c9b-175">However, the data volume per job for this workload is not very big, so you won't observe much throttling by blob storage.</span></span>

### <a name="images-batch-size-per-batch-ai-job"></a><span data-ttu-id="97c9b-176">Batch AI ジョブごとの画像バッチ サイズ</span><span class="sxs-lookup"><span data-stu-id="97c9b-176">Images batch size per Batch AI job</span></span>

<span data-ttu-id="97c9b-177">構成する必要があるもう 1 つのパラメーターは、Batch AI ジョブごとに処理する画像の数です。</span><span class="sxs-lookup"><span data-stu-id="97c9b-177">Another parameter that must be configured is the number of images to process per Batch AI job.</span></span> <span data-ttu-id="97c9b-178">一方では、処理をノード間に広く分散させ、ジョブが失敗した場合に再処理する必要のある画像が多くなりすぎないようにする必要があります。</span><span class="sxs-lookup"><span data-stu-id="97c9b-178">On the one hand, you want to ensure that work is spread broadly across the nodes and that if a job fails, you don't have to retry too many images.</span></span> <span data-ttu-id="97c9b-179">そのためには、多数の Batch AI ジョブを使用して、ジョブごとに処理する画像の数を減らします。</span><span class="sxs-lookup"><span data-stu-id="97c9b-179">That points to having many Batch AI jobs and thus a low number of images to process per job.</span></span> <span data-ttu-id="97c9b-180">しかし他方では、ジョブごとに処理される画像が少なすぎると、セットアップ/起動時間が不釣り合いに大きくなります。</span><span class="sxs-lookup"><span data-stu-id="97c9b-180">On the other hand, if too few images are processed per job, the setup/startup time becomes disproportionately large.</span></span> <span data-ttu-id="97c9b-181">ジョブの数を、クラスター内のノードの最大数と等しくなるように設定することができます。</span><span class="sxs-lookup"><span data-stu-id="97c9b-181">You can set the number of jobs to equal the maximum number of nodes in the cluster.</span></span> <span data-ttu-id="97c9b-182">このようにすると、セットアップ/起動コストの量が最小限になるため、ジョブが失敗しなければ、パフォーマンスは最大になります。</span><span class="sxs-lookup"><span data-stu-id="97c9b-182">This will be the most performant assuming that no jobs fail, because it minimizes the amount of setup/startup cost.</span></span> <span data-ttu-id="97c9b-183">ただし、ジョブが失敗した場合は、多数の画像の再処理が必要になる可能性があります。</span><span class="sxs-lookup"><span data-stu-id="97c9b-183">However, if a job fails, a large number of images might need to be reprocessed.</span></span>

### <a name="file-servers"></a><span data-ttu-id="97c9b-184">ファイル サーバー</span><span class="sxs-lookup"><span data-stu-id="97c9b-184">File servers</span></span>

<span data-ttu-id="97c9b-185">Batch AI を使用する場合は、シナリオに必要なスループットに応じて、複数のストレージ オプションを選択できます。</span><span class="sxs-lookup"><span data-stu-id="97c9b-185">When using Batch AI, you can choose multiple storage options depending on the throughput needed for your scenario.</span></span> <span data-ttu-id="97c9b-186">必要なスループットが低いワークロードでは、(blobfuse を介して) BLOB を使用するので十分なはずです。</span><span class="sxs-lookup"><span data-stu-id="97c9b-186">For workloads with low throughput requirements, using blob storage (via blobfuse) should be enough.</span></span> <span data-ttu-id="97c9b-187">または、Batch AI では管理された単一ノード NFS である Batch AI ファイル サーバーもサポートされており、クラスター ノードに自動的にマウントされて、ジョブに対して一元的にアクセス可能なストレージの場所を提供できます。</span><span class="sxs-lookup"><span data-stu-id="97c9b-187">Alternatively, Batch AI also supports a Batch AI File Server, a managed single-node NFS, which can be automatically mounted on cluster nodes to provide a centrally accessible storage location for jobs.</span></span> <span data-ttu-id="97c9b-188">ほとんどの場合、ワークスペースで必要なファイル サーバーは 1 つだけであり、トレーニング ジョブのデータを異なるディレクトリに分離することができます。</span><span class="sxs-lookup"><span data-stu-id="97c9b-188">For most cases, only one file server is needed in a workspace, and you can separate data for your training jobs into different directories.</span></span> <span data-ttu-id="97c9b-189">単一ノードの NFS がワークロードに適していない場合、Batch AI では、Azure Files または Gluster や Lustre ファイル システムといったカスタム ソリューションなど、他のストレージ オプションがサポートされています。</span><span class="sxs-lookup"><span data-stu-id="97c9b-189">If a single-node NFS isn't appropriate for your workloads, Batch AI supports other storage options, including Azure Files or custom solutions such as a Gluster or Lustre file system.</span></span>

## <a name="security-considerations"></a><span data-ttu-id="97c9b-190">セキュリティに関する考慮事項</span><span class="sxs-lookup"><span data-stu-id="97c9b-190">Security considerations</span></span>

### <a name="restricting-access-to-azure-blob-storage"></a><span data-ttu-id="97c9b-191">Azure Blob Storage へのアクセスの制限</span><span class="sxs-lookup"><span data-stu-id="97c9b-191">Restricting access to Azure blob storage</span></span>

<span data-ttu-id="97c9b-192">この参照アーキテクチャでは、Azure Blob Storage が保護する必要のあるメイン ストレージ コンポーネントです。</span><span class="sxs-lookup"><span data-stu-id="97c9b-192">In this reference architecture, Azure blob storage is the main storage component that needs to be protected.</span></span> <span data-ttu-id="97c9b-193">GitHub リポジトリで示されているベースライン展開では、ストレージ アカウント キーを使用して BLOB ストレージにアクセスしています。</span><span class="sxs-lookup"><span data-stu-id="97c9b-193">The baseline deployment shown in the GitHub repo uses storage account keys to access the blob storage.</span></span> <span data-ttu-id="97c9b-194">さらに制御と保護を強化するには、共有アクセス署名 (SAS) を代わりに使用することを検討します。</span><span class="sxs-lookup"><span data-stu-id="97c9b-194">For further control and protection, consider using a shared access signature (SAS) instead.</span></span> <span data-ttu-id="97c9b-195">これは、ストレージ内のオブジェクトへの制限されたアクセスを付与し、アカウント キーをハード コーディングしたり、それをプレーンテキストで保存したりする必要はありません。</span><span class="sxs-lookup"><span data-stu-id="97c9b-195">This grants limited access to objects in storage, without needing to hard code the account keys or save them in plaintext.</span></span> <span data-ttu-id="97c9b-196">ロジック アプリのデザイナー インターフェイスの内部ではアカウント キーがプレーンテキストで表示されるので、このアプローチは特に便利です。</span><span class="sxs-lookup"><span data-stu-id="97c9b-196">This approach is especially useful because account keys are visible in plaintext inside of Logic App's designer interface.</span></span> <span data-ttu-id="97c9b-197">SAS を使用すると、ストレージ アカウントに適切なガバナンスがあること、およびアクセス権がそれを必要とするユーザーだけに付与されることを保証するのにも役立ちます。</span><span class="sxs-lookup"><span data-stu-id="97c9b-197">Using an SAS also helps to ensure that the storage account has proper governance, and that access is granted only to the people intended to have it.</span></span>

<span data-ttu-id="97c9b-198">ストレージ キーはワークロードのすべての入出力データに対するフル アクセス権を与えるため、データの機密性がさらに高いシナリオでは、すべてのストレージ キーが保護されるようにします。</span><span class="sxs-lookup"><span data-stu-id="97c9b-198">For scenarios with more sensitive data, make sure that all of your storage keys are protected, because these keys grant full access to all input and output data from the workload.</span></span>

### <a name="data-encryption-and-data-movement"></a><span data-ttu-id="97c9b-199">データの暗号化とデータの移動</span><span class="sxs-lookup"><span data-stu-id="97c9b-199">Data encryption and data movement</span></span>

<span data-ttu-id="97c9b-200">この参照アーキテクチャでは、バッチ スコアリング プロセスの例として、スタイルの転送を使用しています。</span><span class="sxs-lookup"><span data-stu-id="97c9b-200">This reference architecture uses style transfer as an example of a batch scoring process.</span></span> <span data-ttu-id="97c9b-201">データの機密性がさらに高いシナリオでは、ストレージに保存されているときのデータを暗号化する必要があります。</span><span class="sxs-lookup"><span data-stu-id="97c9b-201">For more data-sensitive scenarios, the data in storage should be encrypted at rest.</span></span> <span data-ttu-id="97c9b-202">データがある場所から次の場所に移動されるたびに、SSL を使用してデータ転送をセキュリティ保護します。</span><span class="sxs-lookup"><span data-stu-id="97c9b-202">Each time data is moved from one location to the next, use SSL to secure the data transfer.</span></span> <span data-ttu-id="97c9b-203">詳しくは、「[Azure Storage セキュリティ ガイド][storage-security]」をご覧ください。</span><span class="sxs-lookup"><span data-stu-id="97c9b-203">For more information, see [Azure Storage security guide][storage-security].</span></span>

### <a name="securing-data-in-a-virtual-network"></a><span data-ttu-id="97c9b-204">仮想ネットワーク内のデータのセキュリティ保護</span><span class="sxs-lookup"><span data-stu-id="97c9b-204">Securing data in a virtual network</span></span>

<span data-ttu-id="97c9b-205">Batch AI クラスターを展開するときは、仮想ネットワークのサブネット内にプロビジョニングされるようにクラスターを構成できます。</span><span class="sxs-lookup"><span data-stu-id="97c9b-205">When deploying your Batch AI cluster, you can configure your cluster to be provisioned inside a subnet of a virtual network.</span></span> <span data-ttu-id="97c9b-206">これにより、クラスター内のコンピューティング ノードは、他の仮想マシンや、オンプレミスのネットワークとさえ、安全に通信できます。</span><span class="sxs-lookup"><span data-stu-id="97c9b-206">This allows the compute nodes in the cluster to communicate securely with other virtual machines, or even with an on-premises network.</span></span> <span data-ttu-id="97c9b-207">また、BLOB ストレージで[サービス エンドポイント][service-endpoints]を使用して仮想ネットワークからのアクセスを許可したり、Batch AI の VNET 内で単一ノード NFS を使用して、データが常に保護されるようにすることもできます。</span><span class="sxs-lookup"><span data-stu-id="97c9b-207">You can also use [service endpoints][service-endpoints] with blob storage to grant access from a virtual network or use a single-node NFS inside the VNET with Batch AI to ensure that the data is always protected.</span></span>

### <a name="protecting-against-malicious-activity"></a><span data-ttu-id="97c9b-208">悪意のあるアクティビティからの保護</span><span class="sxs-lookup"><span data-stu-id="97c9b-208">Protecting against malicious activity</span></span>

<span data-ttu-id="97c9b-209">複数のユーザーがいるシナリオでは、機密データが悪意のあるアクティビティに対して保護されるようにします。</span><span class="sxs-lookup"><span data-stu-id="97c9b-209">In scenarios where there are multiple users, make sure that sensitive data is protected against malicious activity.</span></span> <span data-ttu-id="97c9b-210">この展開にアクセスして入力データをカスタマイズすることを他のユーザーに許可する場合は、次の注意事項と考慮事項に留意します。</span><span class="sxs-lookup"><span data-stu-id="97c9b-210">If other users are given access to this deployment to customize the input data, take note of the following precautions and considerations:</span></span>

- <span data-ttu-id="97c9b-211">RBAC を使用して、ユーザーのアクセスを必要なリソースのみに制限します。</span><span class="sxs-lookup"><span data-stu-id="97c9b-211">Use RBAC to limit users' access to only the resources they need.</span></span>
- <span data-ttu-id="97c9b-212">2 つのストレージ アカウントを個別にプロビジョニングします。</span><span class="sxs-lookup"><span data-stu-id="97c9b-212">Provision two separate storage accounts.</span></span> <span data-ttu-id="97c9b-213">1 つのアカウントで、入力と出力のデータを格納します。</span><span class="sxs-lookup"><span data-stu-id="97c9b-213">Store input and output data in the first account.</span></span> <span data-ttu-id="97c9b-214">外部ユーザーにはこのアカウントへのアクセスを許可できます。</span><span class="sxs-lookup"><span data-stu-id="97c9b-214">External users can be given access to this account.</span></span> <span data-ttu-id="97c9b-215">もう 1 つのアカウントには、実行可能なスクリプトと出力ログ ファイルを格納します。</span><span class="sxs-lookup"><span data-stu-id="97c9b-215">Store executable scripts and output log files in the other account.</span></span> <span data-ttu-id="97c9b-216">外部ユーザーはこのアカウントにアクセスできないようにします。</span><span class="sxs-lookup"><span data-stu-id="97c9b-216">External users should not have access to this account.</span></span> <span data-ttu-id="97c9b-217">このようにすると、外部ユーザーは実行可能ファイルを変更 (して悪意のあるコードを挿入) することができず、機密情報が保持されている可能性があるログ ファイルにアクセスできません。</span><span class="sxs-lookup"><span data-stu-id="97c9b-217">This will ensure that external users cannot modify any executable files (to inject malicious code), and don't have access to logfiles, which could hold sensitive information.</span></span>
- <span data-ttu-id="97c9b-218">悪意のあるユーザーは、ジョブ キューに対して DDOS を行ったり、不正な形式の有害なメッセージをジョブ キューに挿入したりして、システムをロックさせたりデキュー エラーを発生させたりする可能性があります。</span><span class="sxs-lookup"><span data-stu-id="97c9b-218">Malicious users can DDOS the job queue or inject malformed poison messages in the job queue, causing the system to lock up or causing dequeuing errors.</span></span>

## <a name="monitoring-and-logging"></a><span data-ttu-id="97c9b-219">監視およびログ記録</span><span class="sxs-lookup"><span data-stu-id="97c9b-219">Monitoring and logging</span></span>

### <a name="monitoring-batch-ai-jobs"></a><span data-ttu-id="97c9b-220">Batch AI ジョブの監視</span><span class="sxs-lookup"><span data-stu-id="97c9b-220">Monitoring Batch AI jobs</span></span>

<span data-ttu-id="97c9b-221">ジョブの実行中は、進行状況を監視し、想定どおりに動作していることを確認することが重要です。</span><span class="sxs-lookup"><span data-stu-id="97c9b-221">While running your job, it's important to monitor the progress and make sure that things are working as expected.</span></span> <span data-ttu-id="97c9b-222">ただし、アクティブなノードのクラスター全体を監視するのは困難な場合があります。</span><span class="sxs-lookup"><span data-stu-id="97c9b-222">However, it can be a challenge to monitor across a cluster of active nodes.</span></span>

<span data-ttu-id="97c9b-223">クラスターの全体的な状態を把握するには、Azure Portal の Batch AI ブレードに移動して、クラスター内のノードの状態を検査します。</span><span class="sxs-lookup"><span data-stu-id="97c9b-223">To get a sense of the overall state of the cluster, go to the Batch AI blade of the Azure Portal to inspect the state of the nodes in the cluster.</span></span> <span data-ttu-id="97c9b-224">ノードが非アクティブになった場合、またはジョブが失敗した場合は、エラー ログが BLOB ストレージに保存されており、Azure Portal の [ジョブ] ブレードでもアクセスできます。</span><span class="sxs-lookup"><span data-stu-id="97c9b-224">If a node is inactive or a job has failed, the error logs are saved to blob storage, and are also accessible in the Jobs blade in the Azure Portal.</span></span>

<span data-ttu-id="97c9b-225">ログを Application Insights に接続することで、または別のプロセスを実行して Batch AI クラスターとそのジョブの状態をポーリングすることで、監視をさらに強化できます。</span><span class="sxs-lookup"><span data-stu-id="97c9b-225">Monitoring can be further enriched by connecting logs to Application Insights or by running separate processes to poll for the state of the Batch AI cluster and its jobs.</span></span>

### <a name="logging-in-batch-ai"></a><span data-ttu-id="97c9b-226">Batch AI でのログ</span><span class="sxs-lookup"><span data-stu-id="97c9b-226">Logging in Batch AI</span></span>

<span data-ttu-id="97c9b-227">Batch AI は、関連付けられている BLOB ストレージ アカウントに、すべての stdout/stderr を自動的に記録します。</span><span class="sxs-lookup"><span data-stu-id="97c9b-227">Batch AI will automatically log all stdout/stderr to the associate blob storage account.</span></span> <span data-ttu-id="97c9b-228">Storage Explorer などのストレージ ナビゲーション ツールを使用すると、ログ ファイルをナビゲートするエクスペリエンスがはるかに簡単になります。</span><span class="sxs-lookup"><span data-stu-id="97c9b-228">Using a storage navigation tool such as Storage Explorer will provide a much easier experience for navigating log files.</span></span>

<span data-ttu-id="97c9b-229">この参照アーキテクチャの展開の手順では、さらに簡単なログ記録システムをセットアップする方法も示されています。このシステムでは、次に示すように、さまざまなジョブ全体のすべてのログが、BLOB コンテナー内の同じディレクトリに保存されます。</span><span class="sxs-lookup"><span data-stu-id="97c9b-229">The deployment steps for this reference architecture also shows how to set up a more simple logging system, such that all the logs across the different jobs are saved to the same directory in your blob container, as shown below.</span></span> <span data-ttu-id="97c9b-230">これらのログを使用して、各ジョブおよび各画像の処理にかかった時間を監視します。</span><span class="sxs-lookup"><span data-stu-id="97c9b-230">Use these logs to monitor how long it takes for each job and each image to process.</span></span> <span data-ttu-id="97c9b-231">このようにすると、プロセスをさらに最適化するのにいっそうよい方法を思い付くことができます。</span><span class="sxs-lookup"><span data-stu-id="97c9b-231">This will give you a better sense of how to optimize the process even further.</span></span>

![Azure Batch AI のログ記録のスクリーンショット](./_images/batch-ai-logging.png)

## <a name="cost-considerations"></a><span data-ttu-id="97c9b-233">コストに関する考慮事項</span><span class="sxs-lookup"><span data-stu-id="97c9b-233">Cost considerations</span></span>

<span data-ttu-id="97c9b-234">コストの点では、この参照アーキテクチャで使用されているコンピューティング リソースは、ストレージおよびスケジュール コンポーネントより、はるかに大きい部分を占めます。</span><span class="sxs-lookup"><span data-stu-id="97c9b-234">Compared to the storage and scheduling components, the compute resources used in this reference architecture by far dominate in terms of costs.</span></span> <span data-ttu-id="97c9b-235">主要な課題の 1 つは、GPU 対応マシンのクラスター全体に作業を効果的に並列化することです。</span><span class="sxs-lookup"><span data-stu-id="97c9b-235">One of the main challenges is effectively parallelizing the work across a cluster of GPU-enabled machines.</span></span>

<span data-ttu-id="97c9b-236">Batch AI クラスターのサイズは、キュー内のジョブに応じて、自動的にスケールアップおよびスケールダウンできます。</span><span class="sxs-lookup"><span data-stu-id="97c9b-236">The Batch AI cluster size can automatically scale up and down depending on the jobs in the queue.</span></span> <span data-ttu-id="97c9b-237">2 つの方法のいずれかで、Batch AI の自動スケールを有効にできます。</span><span class="sxs-lookup"><span data-stu-id="97c9b-237">You can enable auto-scale with Batch AI in one of two ways.</span></span> <span data-ttu-id="97c9b-238">プログラムで行う場合は、[展開手順][deployment]の一部である `.env` ファイルで構成できます。または、クラスターを作成した後、ポータルで直接スケール式を変更することもできます。</span><span class="sxs-lookup"><span data-stu-id="97c9b-238">You can do so programmatically, which can be configured in the `.env` file that is part of the [deployment steps][deployment], or you can change the scale formula directly in the portal after the cluster is created.</span></span>

<span data-ttu-id="97c9b-239">即時処理を必要としない作業の場合は、既定の状態 (最小) が 0 個のノードのクラスターであるように、自動スケールの式を構成します。</span><span class="sxs-lookup"><span data-stu-id="97c9b-239">For work that doesn't require immediate processing, configure the auto-scale formula so the default state (minimum) is a cluster of zero nodes.</span></span> <span data-ttu-id="97c9b-240">この構成では、クラスターは 0 個のノードで開始し、キュー内でジョブが検出されたときのみスケールアップします。</span><span class="sxs-lookup"><span data-stu-id="97c9b-240">With this configuration, the cluster starts with zero nodes and only scales up when it detects jobs in the queue.</span></span> <span data-ttu-id="97c9b-241">バッチ スコアリング プロセスが 1 日に数回以下しか発生しない場合は、この設定により大幅なコスト削減を実現できます。</span><span class="sxs-lookup"><span data-stu-id="97c9b-241">If the batch scoring process only happens a few times a day or less, this setting enables significant cost savings.</span></span>

<span data-ttu-id="97c9b-242">非常に短い間隔で発生するバッチ ジョブでは、自動スケールが適切ではない場合があります。</span><span class="sxs-lookup"><span data-stu-id="97c9b-242">Auto-scaling may not be appropriate for batch jobs that happen too close to each other.</span></span> <span data-ttu-id="97c9b-243">クラスターの起動と停止に要する時間にもコストがかかるので、前のジョブの終了後ほんの数分でバッチ ワークロードが開始する場合は、ジョブ間もクラスターを実行したままにする方がコスト効率がよくなる可能性があります。</span><span class="sxs-lookup"><span data-stu-id="97c9b-243">The time that it takes for a cluster to spin up and spin down also incur a cost, so if a batch workload begins only a few minutes after the previous job ends, it might be more cost effective to keep the cluster running between jobs.</span></span>

## <a name="deploy-the-solution"></a><span data-ttu-id="97c9b-244">ソリューションのデプロイ方法</span><span class="sxs-lookup"><span data-stu-id="97c9b-244">Deploy the solution</span></span>

<span data-ttu-id="97c9b-245">この参照アーキテクチャを展開するには、[GitHub リポジトリ][deployment]で説明されている手順に従ってください。</span><span class="sxs-lookup"><span data-stu-id="97c9b-245">To deploy this reference architecture, follow the steps described in the [GitHub repo][deployment].</span></span>

<!-- links -->

[aml-compute]: /azure/machine-learning/service/how-to-set-up-training-targets#amlcompute
[amls]: /azure/machine-learning/service/overview-what-is-azure-ml
[azcopy]: /azure/storage/common/storage-use-azcopy-linux
[batch-ai]: /azure/batch-ai/
[blobfuse]: https://github.com/Azure/azure-storage-fuse
[blob-storage]: /azure/storage/blobs/storage-blobs-introduction
[container-instances]: /azure/container-instances/
[container-registry]: /azure/container-registry/
[deployment]: https://github.com/Azure/batch-scoring-for-dl-models
[dockerhub]: https://hub.docker.com/
[ffmpeg]: https://www.ffmpeg.org/
[image-style-transfer]: https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf
[logic-apps]: /azure/logic-apps/
[service-endpoints]: /azure/storage/common/storage-network-security?toc=%2fazure%2fvirtual-network%2ftoc.json#grant-access-from-a-virtual-network
[source-video]: https://happypathspublic.blob.core.windows.net/videos/orangutan.mp4
[storage-security]: /azure/storage/common/storage-security-guide
[vm-sizes-gpu]: /azure/virtual-machines/windows/sizes-gpu
