---
title: データのパーティション分割のガイダンス
description: パーティションを個別に管理およびアクセスする方法についてのガイダンス
author: dragon119
ms.date: 07/13/2016
pnp.series.title: Best Practices
ms.openlocfilehash: d1d9c1b3cf07f724eb010fc260d86ceb84b789ca
ms.sourcegitcommit: 2e8b06e9c07875d65b91d5431bfd4bc465a7a242
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 02/09/2018
ms.locfileid: "29059974"
---
# <a name="data-partitioning"></a>データのパーティション分割

多くの大規模なソリューションでは、個別に管理およびアクセスできる複数のパーティションにデータが分割されています。 パーティション分割戦略は、メリットを最大限に活かし、悪影響を最小限に抑えるために、入念に選択する必要があります。 パーティション分割は、拡張性を向上させ、競合を少なくし、パフォーマンスを最適化します。 また、使用パターンによってデータを分割するメカニズムを提供できるというメリットもあります。 たとえば、古いデータや使用頻度の低い (コールド) データを廉価なデータ ストレージにアーカイブできます。

## <a name="why-partition-data"></a>データをパーティション分割する理由
クラウドのほとんどのアプリケーションやサービスは、動作の一環としてデータを保存および取得します。 アプリケーションが使用するデータ ストアのデザインは、システムのパフォーマンス、スループット、および拡張性に大きく影響します。 大規模システムで一般的に使用されるテクニックの 1 つは、データを複数のパーティションに分割することです。

> この記事で使用されている *パーティション分割* という用語は、データを異なるデータ ストアに物理的に分割するプロセスを指します。 これは SQL Server テーブルのパーティション分割とは異なります。

データをパーティション分割することは、さまざまなメリットをもたらします。 たとえば、次のニーズを満たすことができます。

* **拡張性の向上**。 単一のデータベース システムをスケールアップすると、最終的には物理的なハードウェア限界に到達します。 データを複数のパーティションに分割し、各パーティションを個別のサーバー上でホストした場合、システムをほとんど無制限にスケールアウトできます。
* **パフォーマンスの向上**。 各パーティションでのデータ アクセス操作は、より少量のデータに対して実行されます。 適切な方法でデータをパーティション分割することにより、システムの効率を高めることができます。 複数のパーティションに影響する操作は、並列に実行できます。 使用するアプリケーションの近くに各パーティションを配置することで、ネットワーク遅延を最小化することができます。
* **可用性の向上**。 データを複数のサーバーにまたがって分割することで、単一障害点を避けることができます。 サーバーで障害が発生するか、計画的なメンテナンスが実行される場合、利用できなくなるのは、そのサーバーのパーティションに格納されているデータだけです。 その他のパーティションでの操作は、続行できます。 パーティションの数を増やすと、単一サーバーの障害が発生しても、利用できなくなるデータの割合は小さくなるので、相対的なインパクトを小さくすることができます。 各パーティションをレプリケートすると、単一パーティション障害が運用に及ぼす影響をさらに小さくすることができます。 また、連続的かつ高度に可用性を保つ必要のある機密データを、可用性の要件と価値の低い (ログ ファイルなどの) データから分離することができます。
* **セキュリティの向上**。 データの特性およびパーティション分割の方法によっては、機密データと非機密データを分割して異なるパーティション、したがって異なるサーバーまたはデータ ストアに格納することが可能です。 こうすることで、特に機密データに対するセキュリティを最適化することができます。
* **運用上の柔軟性の向上**。 パーティション分割は、運用の微調整、管理効率の最大化、およびコストの最小化を達成するための多くの機会を提供します。 たとえば、各パーティションのデータの重要性に基づいて、管理、監視、バックアップと復元、および他の管理タスクについて、異なる戦略を定義することができます。
* **データ ストアと使用パターンの一致**。 パーティション分割では、コストとデータ ストアが提供する組み込み機能に基づいて、各パーティションを異なるタイプのデータ ストアにデプロイできます。 たとえば、大量のバイナリ データを BLOB データ ストアに格納し、構造化されたデータをドキュメント データベースに保持することができます。 詳細については、Microsoft Web サイトで提供されているパターンおよびプラクティス ガイドの「[Building a Polyglot Solution (多言語ソリューションの構築)]」および「[Data access for highly-scalable solutions: Using SQL, NoSQL, and Polyglot Persistence (拡張性の高いソリューション用のデータ アクセス: SQL、NoSQL、および Polyglot の永続化機能の使用)]」を参照してください。

一部のシステムでは、メリットよりもコストの方が大きいと見なされて、パーティション分割が実装されていません。 この論拠の一般的な理由を次に示します。

* 多くのデータ ストレージ システムは、パーティション間にまたがる結合をサポートしません。また、パーティション化されたシステムでは参照整合性を維持することは困難になる可能性があります。 (パーティション分割レイヤーの) アプリケーション コードで結合や整合性チェックを頻繁に実装する必要があります。この結果、余分に I/O が発生したり、アプリケーションの複雑度が大きくなったりする可能性があります。
* パーティションを維持する作業は、必ずしも簡単なタスクではありません。 データの揮発性が高いシステムでは、パーティションを定期的に再調整し、競合とホット スポットを少なくする必要があります。
* 一部の一般的なツールは、パーティション化されたデータに対して、そのままでは動作しません。

## <a name="designing-partitions"></a>パーティションの設計
データは、水平的パーティション分割、垂直的パーティション分割、または機能的パーティション分割の方法でパーティション分割することができます。 選択する戦略は、データをパーティション分割する理由、およびデータを使用するアプリケーションとサービスの要件によって決定されます。

> [!NOTE]
> このガイダンスで取り上げられているパーティション分割構成は、基になるデータ ストレージ テクノロジに依存しない方法で説明されます。 それらの構成は、リレーショナル データベースおよび NoSQL データベースを含む多くのタイプのデータ ストアに適用できます。
>
>

### <a name="partitioning-strategies"></a>パーティション分割戦略
データをパーティション分割する際に使用される、典型的な 3 つの戦略を次に示します。

* **水平的パーティション分割** (しばしば "*シャーディング*" と呼ばれます)。 この戦略では、各パーティションは、自身の権限を持つデータ ストアですが、すべてのパーティションは同じスキーマを持ちます。 各パーティションは "*シャード*" と呼ばれ、データの特定のサブセット、たとえば、e コマース アプリケーションにおける特定の顧客グループのすべての注文などを保持します。
* **垂直的パーティション分割**。 この戦略では、各パーティションはデータ ストアに含まれる項目のフィールドのサブセットを含みます。 フィールドは、それらの使用パターンに従って分割されます。 たとえば、頻繁にアクセスされるフィールドを 1 つの垂直的パーティションに、使用頻度の少ないフィールドをまとめて別の垂直的パーティションに配置します。
* **機能的パーティション分割**。 この戦略では、システム内の区分可能な各コンテキストによって使用される方法に従って、データは集約されます。 たとえば、請求処理と製品在庫の管理用に複数の個別のビジネス機能を実装する e コマース システムでは、請求データを 1 つのパーティションに、製品在庫データを別のパーティションに格納することができます。

ここで説明する 3 つの戦略は、組み合わせて使用できることに注意してください。 これらの戦略は相互に排他的ではなく、パーティション分割構成を設計する際には、これらすべてを考慮することをお勧めします。 たとえば、データをシャードに分割し、次に垂直的パーティション分割を使用して、各シャード内のデータをさら分割することができます。 同様に、機能的パーティション分割内のデータをシャードに分割することもできます (垂直的にパーティション分割することもできます)。

ただし、各戦略の異なる要件により、いくつかの競合する問題が発生することがあります。 システムの全体的なデータ処理パフォーマンス目標を満たすパーティション分割構成を設計するときに、すべての戦略を評価および調整する必要があります。 以降のセクションでは、各戦略について、さらに詳細に説明します。

### <a name="horizontal-partitioning-sharding"></a>水平的パーティション分割 (シャーディング)
図 1 は、水平的パーティション分割またはシャーディングの概要を示します。 この例では、製品在庫データが製品キーに基づいてシャードに分割されます。 各シャードは、シャード キーの連続する範囲 (A ～ G および H ～ Z) のデータを保持し、アルファベット順に編成されます。

![パーティション キーに基づく水平的パーティション分割 (シャーディング) データ](./images/data-partitioning/DataPartitioning01.png)

*図 1: パーティション キーに基づく水平的パーティション分割 (シャーディング) データ*

シャーディングを使用して負荷をより多くのコンピューターに分散することにより、競合を少なくし、パフォーマンスを向上させることができます。 別のサーバーで動作するシャードをさらに追加することで、システムをスケールアウトすることができます。

このパーティション分割戦略を実装する場合に最も重要な要因は、シャーディング キーを選択する方法です。 システムが運用状態に移行した後にキーを変更することは、非常に困難になる可能性があります。 キーは、ワークロードがシャード間で可能な限り均等になるようにデータがパーティション分割されるものである必要があります。

シャード間でデータ量が同じになるようにする必要はありません。 要求の数が均等になるようにすることの方が重要です。 シャードにより、大量の項目が格納されていても各項目へのアクセス操作は少ないものや、 項目数は少なくても各項目へのアクセスは非常に頻繁に発生するものがあります。 また、単一のシャードが、シャードをホストするために使用されているデータ ストアのスケール制限を (容量と処理リソースの観点で) 超えないようにする必要があります。

シャーディング構成を使用する場合は、パフォーマンスと可用性に影響する可能性のあるホットスポット (またはホット パーティション) が作成されないようにする必要があります。 たとえば、顧客の名前の最初の文字ではなく、顧客 ID のハッシュを使用する場合は、使用頻度にばらつきのある先頭文字を使用することにより発生する不均等を防ぐことができます。 これは、データをパーティション間で均等に分散するために役立つ典型的な手法です。

将来、大きなシャードを小さなシャードに分割する、小さなシャードをマージして大きなシャードにする、またはシャード セットに格納されているデータを定義するスキーマを変更する、などの要件ができるだけ発生しないような、シャーディング キーを選択します。 これらの操作は非常に時間がかかる可能性があり、実行時に 1 つ以上のシャードをオフラインにすることが必要になる場合があります。

シャードをレプリケートすると、他のシャードの分割、マージ、または再構成を行うときに、一部のレプリカをオンラインにしておくことができる場合があります。 ただし、再構成が行われているときには、これらのシャードに含まれるデータ上で実行できる操作を制限することが必要になることがあります。 たとえば、シャードの再構成時には、レプリカのデータを読み取り専用にして、不整合の発生を防ぐことが必要になる場合があります。

> これらの考慮事項の多くについての詳細やガイダンス、および水平的パーティション分割を実装するデータ ストアを設計するためのベスト プラクティス手法については、「 [Sharding Pattern (シャーディング パターン)]」を参照してください。
>
>

### <a name="vertical-partitioning"></a>垂直的パーティション分割
垂直的パーティション分割を使用する最も一般的な目的は、最も頻繁にアクセスされる項目をフェッチする操作に関連する I/O とパフォーマンスのコストを削減することです。 図 2 は、垂直的パーティション分割の例です。 この例では、各データ項目のさまざまなプロパティが異なるパーティションで保持されています。 一方のパーティションには、製品の名前、説明、価格情報といったアクセス頻度の高いデータが保持されています。 他のパーティションには、在庫量や最終注文日が保持されています。

![使用パターンによるデータの垂直的パーティション分割](./images/data-partitioning/DataPartitioning02.png)

*図 2: 使用パターンによるデータの垂直的パーティション分割*

この例では、アプリケーションは、製品の詳細を顧客に表示する際は常に、製品の名前、説明、および価格をクエリします。 在庫レベルおよび製造元からの最終注文日の 2 つの項目は通常一緒に使用されるので、別のパーティションに保持されています。

このパーティション分割構成のメリットは、変動することが比較的少ないデータ (製品の名前、説明、および価格) を、より動的なデータ (在庫レベルおよび最終注文日) から分離していることです。 アプリケーションにとっては、変動することの少ないデータが頻繁にアクセスされる場合に、それらをメモリ上にキャッシュできるというメリットがあります。

このパーティション分割戦略の別の典型的なシナリオは、機密データのセキュリティを最大化することです。 たとえば、クレジット カードの番号とセキュリティ コードをそれぞれ別のパーティションに格納することで、それを実現できます。

垂直的パーティション分割は、データに対して必要な同時アクセスの量を減らすこともできます。

> 垂直的パーティション分割は、データ ストア内のエンティティ レベルで動作します。エンティティを部分的に正規化して、"*多数の*" 項目で構成されるエンティティを "*少数の*" 項目で構成される複数のエンティティに分割します。 垂直的パーティション分割は、HBase や Cassandra など、列指向のデータ ストアに理想的に適しています。 変化する可能性が低い列コレクションのデータの場合は、SQL Server の列ストアを使用することも検討してください。
>
>

### <a name="functional-partitioning"></a>機能的パーティション分割
アプリケーションで各ビジネス エリアまたはサービスの区分のあるコンテキストを識別できる場合、機能的パーティション分割は、分離とデータ アクセスのパフォーマンスを向上する手法を提供します。 機能的パーティション分割の別の一般的な使用法は、読み書き可能なデータをレポート目的で使用される読み取り専用データから分離することです。 図 3 は、機能的パーティション分割の概要を示しており、在庫データが顧客データから分離されています。

![区分のあるコンテキストまたはサブドメインによりデータが分割された機能的パーティション分割](./images/data-partitioning/DataPartitioning03.png)

*図 3: 区分のあるコンテキストまたはサブドメインによりデータが分割された機能的パーティション分割*

このパーティション分割戦略は、システムのさまざまな部分にまたがるデータ アクセスの競合を少なくするのに役立ちます。

## <a name="designing-partitions-for-scalability"></a>拡張性の観点でのパーティション分割の設計
各パーティションのサイズとワークロードを考慮して、それらを均等に分散することにより、最大の拡張性を達成することが重要です。 ただし、データのパーティションが単一のパーティション ストアの拡張制限を超えないようにすることも必要です。

拡張性の観点でパーティション分割を設計する際には、次の手順に従います。

1. アプリケーションを分析して、各クエリで返される結果セットのサイズ、アクセス頻度、固有の遅延時間、サーバー側のコンピューティング処理要件など、データ アクセス パターンを理解します。 多くの場合、少数の主要なエンティティが最大の処理リソースを要求します。
2. この分析を使用して、データ サイズやワークロードなどの現在および将来の拡張性目標を決定します。 そして、拡張性目標を満たすようにパーティション全体にデータを分散します。 水平的パーティション分割戦略では、均等に分散するために適切なシャード キーを選択する必要があります。 詳細については、「 [Sharding Pattern (シャーディング パターン)]」を参照してください。
3. 各パーティションで利用できるリソースが、データ サイズとスループットの観点で拡張性の要件を満たすことを確認します。 たとえば、パーティションをホストしているノードで、ストレージ領域、処理能力、またはネットワーク帯域幅のサイズに関してハード面の制限があることがあります。 ストレージと処理能力の要件がこれらの制限を超える可能性がある場合、パーティション分割戦略を再調整するか、データをさらに分割することが必要になることがあります。 たとえば、1 つの拡張性アプローチとして、ログ データを主要なアプリケーション機能から分離することがあります。 そのためには、別のデータ ストアを使用して、データ ストレージ全体での要件がノードの拡張性制限を超えないようにします。 データ ストアの総数がノード制限を超える場合、別のストレージ ノードを使用することが必要になる場合があります。
4. 使用中のシステムを監視して、データが想定どおりに分散されており、それぞれのパーティションで負荷が適切に処理されていることを検証します。 使用状況が分析で期待されたものと一致しない場合があります。 そのような場合、パーティションを再調整できることがあります。 再調整できない場合、必要とされる均等性を達成するために、システムの一部を再設計することが必要になる場合があります。

クラウド環境によっては、リソースがインフラストラクチャ境界の観点で割り当てられることに注意してください。 選択した境界の制限が、データ ストレージ、処理能力、および帯域幅の観点で、データ量の想定される成長を収容できることを確認する必要があります。

たとえば、Azure Table Storage を使用する場合、アクセス頻度の高いシャードは単一パーティションが要求を処理するために利用できるリソースよりも多くのリソースを必要とすることがあります (一定期間内に単一パーティションで処理できる要求の量には制限があります。 詳細については、Microsoft Web サイトの「[Azure Storage のスケーラビリティおよびパフォーマンスのターゲット]」のページを参照してください。

 この場合、負荷を分散するために、シャードを再パーティション分割することが必要な場合があります。 これらのテーブルの合計サイズまたはスループットがストレージ アカウントの容量を超える場合、追加のストレージ アカウントを作成して、テーブルをそれらのアカウント全体で分散することが必要な場合があります。 ストレージ アカウントの数がサブスクリプションで利用できるストレージ アカウントの数を超える場合、複数のサブスクリプションを使用することが必要な場合があります。

## <a name="designing-partitions-for-query-performance"></a>クエリ パフォーマンスの観点でのパーティション分割の設計
クエリのパフォーマンスは、多くの場合、小さなデータ セットを使用し、並列クエリを実行することで、格段に向上できます。 各パーティションには、データ セット全体の小さな割合を収容する必要があります。 そうすると、容量が小さくなるので、クエリのパフォーマンスが向上します。 ただし、パーティション分割は、データベースを適切に設計および構成することの代替にはなりません。 たとえば、リレーショナル データベースを使用している場合は、必要なインデックスが構成されていることを確認します。

クエリ パフォーマンスの観点でパーティション分割を設計する際には、次の手順に従います。

1. アプリケーションの要件とパフォーマンスを検証します。
   * ビジネス要件を使用して、常に高速に実行する必要のある重要なクエリを決定します。
   * システムを監視して、低速で実行するクエリを識別します。
   * 最も頻繁に実行されるクエリを見つけます。 各クエリの単一インスタンスのコストは少ない場合でも、累積されたリソース消費量は非常に大きくなる場合があります。 これらのクエリによって取得されるデータを個別のパーティションまたはキャッシュに配置することが適切な場合があります。
2. パフォーマンスの低下を引き起こしているデータをパーティション分割します。
   * クエリの応答時間がターゲット時間内になるように各パーティションのサイズを制限します。
   * 水平的パーティション分割を実装しようとしている場合、アプリケーションが簡単にパーティションを見つけられるようにシャード キーを設計します。 これにより、クエリがすべてのパーティションを通してスキャンする必要がなくなります。
   * パーティションの場所を検討してください。 可能な限り、パーティションのデータを、それにアクセスするアプリケーションやユーザーに地理的に近い場所に維持します。
3. エンティティにスループットとクエリ パフォーマンスの要件がある場合、そのエンティティに基づく機能的パーティション分割を使用します。 それでも要件が満たされない場合は、水平的パーティション分割も適用します。 ほとんどの場合、単一のパーティション分割戦略で十分ですが、両方の戦略を組み合わせて使用することが効果的な場合があります。
4. パフォーマンスを向上させるために、パーティション全体で並列に実行する非同期クエリを使用することを検討します。

## <a name="designing-partitions-for-availability"></a>可用性の観点でのパーティション分割の設計
データをパーティション分割すると、データセット全体が単一障害点となることはなく、またデータセットの個々のサブセットを個別に管理できるので、アプリケーションの可用性が向上します。 機密データを含んでいるパーティションをレプリケートすることでも、可用性を向上できます。

パーティションを設計および実装する際には、可用性に影響する次の要因を検討します。

* **業務に対するデータの重要度**。 一部のデータは、請求書の詳細や銀行取引情報など、ビジネス上の機密情報を含むことがあります。 その他のデータは、ログ ファイルやパフォーマンス トレースなど、単純に機密性の低い運用データである可能性があります。 各データの種類を識別したら、次の点を考慮します。
  * 機密データを可用性の高いパーティションに格納し、適切なバックアップ プランを構築します。
  * 各データセットのさまざまな重要度に応じて、個別の管理および監視のメカニズムまたは手順を確立します。 同じレベルの重要度を持つデータを同じパーティションに配置して、適切な頻度で一緒にバックアップできるようにします。 たとえば、銀行取引のデータを保持するパーティションでは、ログ情報またはトレース情報を保持するパーティションよりも頻繁にバックアップすることが必要な場合があります。
* **個々のパーティションを管理する方法**。 個別に管理および保守ができるようにパーティションを設計すると、いくつかのメリットが生じます。 例: 
  * 1 つのパーティションで障害が発生した場合、他のパーティションのデータにアクセスするアプリケーションのインスタンスに影響を及ぼすことなく、そのパーティションを個別に復旧できます。
  * 地理的な場所に基づいてデータをパーティション分割すると、各場所のオフピーク時間に保守タスクが実行されるようにスケジュールできます。 計画された保守タスクがこの期間内に完了するように、パーティションのサイズが大きすぎないことを確認します。
* **機密データをパーティション全体でレプリケートすることの必要性**。 この戦略は、可用性とパフォーマンスを向上させますが、整合性に関して問題を発生させることもあります。 パーティションのデータに対して行われた変更がすべてのレプリカと同期されるには時間がかかります。 この期間は、さまざまなパーティションが異なるデータ値を持つ可能性があります。

## <a name="understanding-how-partitioning-affects-design-and-development"></a>設計および開発へのパーティション分割の影響
パーティション分割を使用すると、システムの設計および開発で複雑さが増大します。 初期においてシステムが単一のパーティションのみを含んでいる場合でも、パーティション分割をシステム設計の基盤として考慮する必要があります。 システムでパフォーマンスおよび拡張性の問題が発生しだしてから、パーティション分割を付け足しで構築しようとすると、保守する必要のあるライブ システムが既に存在するので、複雑さが大きくなります。

この環境でパーティション分割に対応できるようにシステムを更新する場合、データ アクセス ロジックを変更する必要があります。 また、ユーザーがシステムを使い続けることができると期待している期間に、大量の既存データをパーティション全体に分散して移行する必要もあります。

場合によっては、初期のデータ セットが小さく、単一サーバーで容易に処理できるので、パーティション分割は重要ではないと見なされます。 これは、システムが初期サイズを超えてスケールすることはないと想定されるシステムでは正しいですが、多くの商用システムでは、ユーザー数の増加に従って、拡張することが必要になります。 この拡張は、一般的に、データ量の増加を伴います。

パーティション分割は必ずしも大規模データ ストア用の機能ではないことを理解することも重要です。 たとえば、小さなデータ ストアが数百の同時クライアントによって過度にアクセスされることがあります。 このような状況でデータをパーティション分割すると、競合を少なくし、スループットを向上させることができます。

データパーティション分割構成を設計する際には、次の点を考慮する必要があります。

* **可能な限り、最も頻度の高いデータベース操作で対象となるデータを各パーティションで一緒になるように配置して、パーティションをまたがるデータ アクセス操作を最小限にします**。 パーティションをまたがるクエリは、単一パーティション内だけのクエリよりも時間がかかることがあります。また、あるクエリ セットに対してパーティションを最適化すると、別のクエリ セットが悪影響を受けることがあります。 パーティションをまたがるクエリを回避できない場合は、並列クエリを実行することによってクエリ時間を最小限に、アプリケーション内で結果を集計します。 この方法は状況によっては実現できないことがあります。たとえば、あるクエリの結果を取得して、次のクエリで使用することが必要な場合です。
* **クエリで、郵便番号表や製品リストなど比較的静的な参照データが使用される場合、すべてのパーティションでこのデータをレプリケートして、それぞれのパーティションで個別の検索操作が必要にならないようにすることを検討します**。 この方法は、参照データが、システム全体からの過度なトラフィックの対象である "ホット" データセットになる可能性も小さくします。 ただし、この参照データに対して発生する可能性のあるあらゆる変更を同期化することに伴う追加コストも発生します。
* **可能な限り、垂直的パーティション間、および機能的パーティション間での参照整合性の要件を最小化します**。 これらの構成では、データが更新および消費された場合に、パーティション間での参照整合性を、アプリケーション自体が維持する必要があります。 複数のパーティション間でデータを結合する必要のあるクエリは、同一パーティション内でのみデータを結合するクエリよりも低速に実行します。これは、アプリケーションが一般的に、キーに基づいてクエリを実行し、続いて外部キーに基づいてクエリを実行する必要があるためです。 このような状況では、パーティション分割の代わりに、関連するデータのレプリケートまたは非正規化を検討します。 パーティション間結合が必要な場合にクエリ時間を最小化するには、パーティション上で並列クエリを実行し、データをアプリケーション内で結合します。
* **パーティション分割構成がパーティション間のデータ整合性に及ぼす影響を考慮します。** 強力な整合性が実際に要件であるかどうかを評価します。 クラウドでの一般的な手法では、強力な整合性の代わりに、結果整合性を実装します。 各パーティションのデータは個別に更新され、アプリケーションのロジックはすべての更新が正常に完了したことを確認します。 また、結果整合性の操作が実行している間、データをクエリすることにより発生する可能性のある不整合を処理することができます。 結果整合性を実装する方法の詳細については、「 [Data consistency primer (データ整合性入門) (データ整合性入門)]」を参照してください。
* **クエリが正しいパーティションを見つける方法を考慮します**。 必要なデータを見つけるためにクエリがすべてのパーティションをスキャンする必要がある場合、複数の並列クエリが実行中である場合でも、パフォーマンスに非常に大きな影響を及ぼします。 垂直的パーティション分割および機能的パーティション分割と共に使用されるクエリは、本質的にパーティションを指定できますが、 水平的パーティション分割 (シャーディング) が使用される場合、すべてのシャードが同じスキーマを持つので、項目を見つけることが困難になる可能性があります。 シャーディングに対する一般的な解決法は、データの特定の項目のシャード場所を検索するために使用できるマップを維持することです。 このマップは、アプリケーションのシャーディング ロジックに実装することも、データ ストアが透過的シャーディングをサポートする場合にはデータ ストアにより維持されるようにすることもできます。
* **水平的パーティション分割戦略を使用する場合、シャードを定期的に再調整します**。 これにより、サイズおよびワークロードが均等になるようにデータを分散することにより、ホットスポットの最小化、クエリ パフォーマンスの最大化、および物理ストレージ制限の回避を達成します。 ただし、これは複雑なタスクで、多くの場合、カスタム ツールまたはカスタム プロセスの使用が必要になります。
* **各パーティションをレプリケートする場合、障害に対する保護能力が高まります**。 単一のレプリカで障害が発生しても、動作しているコピーにクエリを振り向けることができます。
* **パーティション分割戦略の物理制限に到達した場合、拡張性を別のレベルに拡張することが必要な場合があります**。 たとえば、パーティション分割がデータベース レベルで行われる場合、パーティションを複数のデータベースで配置したりレプリケートしたりすることが必要になる場合があります。 パーティション分割が既にデータベース レベルで行われており、物理制限が問題になっている場合、パーティションを複数のホスティング アカウントで配置したりレプリケートしたりすることが必要な可能性があります。
* **トランザクションでは、複数のパーティションのデータにアクセスしないようにします**。 一部のデータ ストアには、データを変更する操作に対してトランザクション レベルの一貫性と整合性を保つ機能を実装していますが、これが有効になるのは、データが単一のパーティションに配置されている場合だけです。 複数のパーティションにまたがってトランザクション レベルのサポートを必要とする場合、ほとんどのパーティション分割システムでこの機能はネイティブにサポートされていないので、アプリケーション ロジックの一部として実装することが必要になる可能性があります。

すべてのデータ ストアで運用の管理および監視のアクティビティが必要です。 これらのタスクには、データのロード、データのバックアップおよび復元、データの再編成、システムが正しく効率よく動作していることの確認などがあります。

運用管理に影響する次の要因を考慮してください。

* **データをパーティション分割するとき、適切な管理と運用のタスクを実装する方法**。 バックアップと復元、データのアーカイブ、システムの監視、その他の管理タスクなどです。 たとえば、バックアップと復元の操作では論理的な一貫性を維持することが課題になります。
* **データを複数のパーティションにロードする方法と、他のソースから到着する新しいデータを追加する方法**。 一部のツールおよびユーティリティでは、データを正しいパーティションにロードするなど、シャード化されているデータの操作がサポートされていないことがあります。 このため、新しいツールおよびユーティリティの作成または取得が必要になることがあります。
* **定期的にデータをアーカイブして削除する方法**。 パーティションの過度な成長を防止するために、定期的に (たとえば、月単位で) データをアーカイブして削除する必要があります。 異なるアーカイブ スキーマに一致するように、データを変換することが必要な場合があります。
* **データ整合性の問題を見つける方法**。 あるパーティションに存在するデータが別のパーティションに存在しない情報を参照しているなど、データ整合性の問題を見つけるプロセスを定期的に実行することを検討します。 このようなプロセスでは、問題を自動的に修復するか、問題を手動で修正してもらうために、オペレーターに警告を発行するかのいずれかを実装できることがあります。 たとえば、e コマース アプリケーションでは、注文情報が 1 つのパーティションで保持されているが、各注文を構成する行項目が別のパーティションで保持されていることがあります。 注文を格納するプロセスは、データを両方のパーティションに追加する必要があります。 このプロセスに障害が発生すると、対応する注文のない行項目が格納される可能性があります。

一般的に、データ ストレージ テクノロジそれぞれに、パーティション分割をサポートするための独自の機能があります。 次のセクションでは、Azure アプリケーションで一般的に使用されるデータ ストアによって実装されるオプションの概要について説明します。 これらの機能を最大限に活用できるようにアプリケーションを設計するための考慮事項についても説明します。

## <a name="partitioning-strategies-for-azure-sql-database"></a>Azure SQL Database 用のパーティション分割戦略
Azure SQL Database はクラウドで動作するサービスとしてのリレーショナル データベースです。 Microsoft SQL Server を基盤にしています。 リレーショナル データベースでは、情報はテーブルに分割されます。各テーブルは、エンティティに関する情報を一連の行として保持します。 各行には、エンティティの個々のフィールドのデータを保持する列が含まれます。 Microsoft Web サイトの「[SQL Database とは SQL Database の概要、技術の詳細、DTU の説明]」のページでは、SQL データベースの作成と使用に関する詳細な資料が提供されています。

## <a name="horizontal-partitioning-with-elastic-database"></a>Elastic Database での水平的パーティション分割
1 つの SQL データベースには保持できるデータ量に制限があります。 スループットにはアーキテクチャ上の要因とアーキテクチャがサポートする同時接続数による制約があります。 SQL Database の Elastic Database 機能は、SQL データベースの水平スケーリングをサポートします。 Elastic Database を使用することで、複数の SQL データベースにまたがってデータをシャードにパーティション分割できます。 また、処理する必要のあるデータ量が増加または減少する場合にシャードを追加または削除できます。 さらに、Elastic Database を使用して負荷をデータベース全体に分散することにより、競合を少なくすることもできます。

> [!NOTE]
> Elastic Database は、Azure SQL Database の Federations 機能に代わるものです。 既存の SQL Database Federations のインストール環境は、Federations 移行ユーティリティを使用して Elastic Database に移行できます。 また、Elastic Database によって提供される機能がユーザーのシナリオに本質的に適合しない場合は、独自のシャーディング メカニズムを実装することもできます。
>
>

各シャードは、SQL データベースとして実装されます。 1 つのシャードは、"*シャードレット*" と呼ばれる複数のデータセットを保持できます。 各データベースは、それが含むシャードレットを定義するメタデータを維持します。 シャードレットは単一のデータ項目であることも、同じシャードレット キーを共有する項目グループであることもできます。 たとえば、マルチテナント アプリケーションでデータをシャーディングしている場合、シャードレット キーをテナント ID にし、特定のテナントのすべてのデータを同じシャードレットの一部として保持することができます。 他のテナントのデータは、異なるシャードレットに保持されます。

プログラマーは、データセットをシャードレット キーに関連付ける処理を実装する必要があります。 個別の SQL データベースは、グローバル シャード マップ マネージャーとして機能します。 このデータベースには、システム内のすべてのシャードとシャードレットの一覧が含まれています。 データにアクセスするクライアント アプリケーションは、最初に、グローバル シャード マップ マネージャー データベースに接続し、シャード マップ (シャードとシャードレットの一覧) のコピーを取得して、ローカルにキャッシュします。

次に、アプリケーションはこの情報を使用して、データ要求を該当するシャードに転送します。 この機能は、NuGet パッケージとして利用できる Azure SQL Database Elastic Database Client Library に含まれる一連の API の背後に隠されています。 Elastic Database の包括的な情報については、Microsoft Web サイトの「 [Elastic Database 機能の概要] 」を参照してください。

> [!NOTE]
> グローバル シャード マップ マネージャー データベースをレプリケートすることにより、遅延を小さくし、可用性を向上させることができます。 Premium 価格レベルの 1 つを使用してデータベースを実装する場合、アクティブ geo レプリケーションを構成して、データを異なるリージョン内のデータベースに連続してコピーできます。 ユーザーが存在する各リージョンにデータベースのコピーを作成します。 そして、このコピーに接続してシャード マップを取得するようにアプリケーションを構成します。
>
> 別の方法として、Azure SQL データ同期または Azure Data Factory パイプラインを使用して、リージョン間でシャード マップ マネージャー データベースをレプリケートします。 この形態のレプリケーションは定期的に実行され、シャードマップの変更がまれな場合に適しています。 さらに、シャード マップ マネージャー データベースは、Premium の価格レベルを使用して作成する必要はありません。
>
>

Elastic Database では、データをシャードレットにマップし、シャードに格納するために、2 つの構成を利用できます。

* **リスト シャード マップ** は、単一キーとシャードレットとの間の関連を定義します。 たとえば、マルチテナント システムで、各テナント用のデータを一意のキーに関連付けて、独自のシャードレットに格納することができます。 プライバシーと分離を保証するために (つまり、テナントが別のテナントに提供されているデータ ストレージ リソースを枯渇させないようにするために)、各シャードレットは独自のシャード内に保持できます。

![リスト シャード マップを使用してテナント データを個別のシャードに格納](./images/data-partitioning/PointShardlet.png)

*図 4: リスト シャード マップを使用してテナント データを個別のシャードに格納*

* **範囲シャード マップ** は、一連の連続するキー値とシャードレットとの間の関連を定義します。 前に取り上げたマルチテナントの例で、専用のシャードレットを実装する代わりに、それぞれに独自のキーを持つ一連のテナントのデータを、同一のシャードレット内にグループ化できます。 この構成は、複数のテナントがデータ ストレージ リソースを共有するので、最初の構成よりも安価ですが、データのプライバシーと分離が維持できなくなるリスクもあります。

![範囲シャードマップを使用してある範囲のテナントのデータを 1 つのシャードに格納](./images/data-partitioning/RangeShardlet.png)

*図 5: 範囲シャードマップを使用してある範囲のテナントのデータを 1 つのシャードに格納*

単一のシャードは複数のシャードレットのデータを含むことができることに注意してください。 たとえば、リスト シャードレットを使用してさまざまな非連続テナントのデータを同一のシャードに格納できることがあります。 同一のシャード内で範囲シャードレットとリスト シャードレットを混在させることもできます。ただし、それぞれは、グローバル シャード マップ マネージャー データベースの別のマップを通してアドレス指定されます (グローバル シャード マップ マネージャー データベースは、複数のシャード マップを含むことができます)。図 6 は、この手法を説明しています。

![複数のシャード マップの実装](./images/data-partitioning/MultipleShardMaps.png)

*図 6: 複数のシャード マップの実装*

パーティション分割構成の実装方法によっては、システムのパフォーマンスに非常に大きな影響を与えることがあります。 また、シャードの追加/削除の頻度、またはシャード全体でデータを再パーティション分割する必要がある頻度にも影響を及ぼします。 Elastic Database を使用してデータをパーティション分割するときは、次の点を考慮する必要があります。

* 一緒に使用されるデータを同一のシャードにグループ化し、複数のシャードに保持されているデータにアクセスする必要のある操作が発生しないようにします。 Elastic Database では、シャードは独自の権限を持つ SQL データベースで、Azure SQL Database はデータベース間結合 (クライアント側で実行される必要があります) をサポートしません。 また、Azure SQL Database では、1 つのデータベース内の参照整合性制約、トリガー、およびストアド プロシージャは、別のデータベースのオブジェクトを参照できません。 このため、シャード間に依存関係のあるシステムを設計しないでください。 ただし、SQL データベースでは、クエリや他の操作で頻繁に使用される参照データのコピーを保持するテーブルを持つことができます。 これらのテーブルは、特定のシャードレットに属する必要はありません。 このデータをシャード間でレプリケートすると、データベースをまたがってデータを結合する必要性をなくすことができる可能性があります。 理想的には、そのようなデータは静的であるか移動頻度が低く、レプリケーション負荷が最小であり、無効となる機会がないものにする必要があります。

  > [!NOTE]
  > SQL Database はデータベース間結合をサポートしませんが、Elastic Database API を使用すると、シャード間クエリを実行できます。 これらのクエリは、シャード マップにより参照されるすべてのシャードレットに保持されているデータ全体を透過的に反復処理できます。 Elastic Database API はシャード間クエリを一連の個々のクエリ (データベースごとに 1 つずつ) に分割し、結果をマージします。 詳細については、Microsoft Web サイトの「 [マルチシャード クエリ実行] 」のページを参照してください。
  >
  >
* 同じシャードマップに属するシャードレットに格納されるデータは、同じスキーマを持つ必要があります。 たとえば、テナント データを含むシャードレットと製品情報を含む別のシャードレットをポイントするようなリスト シャードマップを作成しないでください。 このルールは Elastic Database によって強制されませんが、各シャードレットに異なるスキーマが存在すると、データ管理とクエリが非常に複雑になります。 前の例では、2 つのリスト シャード マップを作成する必要があります。1 つはテナント データを参照し、他の 1 つは製品情報を指します。 異なるシャードレットに属するデータを、同じシャードに格納できることに注意してください。

  > [!NOTE]
  > Elastic Database API のシャード間クエリ機能は、同じスキーマを含むシャード マップ内の各シャードレットに依存します。
  >
  >
* トランザクション操作は、同一のシャード内で保持されているデータを対象にする場合にのみサポートされます。シャード間ではサポートされません。 トランザクションは、シャードレットをまたがってデータにアクセスできますが、シャードレットが同一のシャードに属する場合に限られます。 このため、ビジネス ロジックがトランザクションを実行する必要がある場合、影響を受けるデータを同一のシャードに格納するか、または結果整合性を実装します。 詳細については、「 [Data consistency primer (データ整合性入門) (データ整合性入門)]。
* シャードを、シャードのデータにアクセスするユーザーの近くに配置します (geo 配置シャード)。 この戦略は、遅延を小さくするのに役立ちます。
* アクセス頻度の非常に高いシャード (ホットスポット) と低いシャードが混在しないようにします。 シャード間で負荷が均等に分散されるようにします。 これを行うには、シャードレット キーをハッシュ処理することが必要になることがあります。
* geo 配置シャードを実装する場合、ハッシュ処理されたキーが、データにアクセスするユーザーの近くに格納されているシャードに保持されているシャードレットにマッピングすることを確認する必要があります。
* 現在、限定された SQL データ型 (*int、bigint、varbinary*、および *uniqueidentifier*) のみがシャードレット キーとしてサポートされます。 SQL の *int* 型と *bigint* 型は C# の *int* データ型と *long* データ型に対応し、数値の範囲も同じです。 SQL の *varbinary* 型は C# で *Byte* 配列を使用して処理することができ、SQL の *uniqueidentier* 型は、.NET Framework の *Guid* クラスに対応します。

名前が示すように、Elastic Database を使用すると、データ量が増加または減少するに従って、シャードを追加または削除することができます。 Azure SQL Database Elastic Database クライアント ライブラリの API を使用すると、アプリケーションからシャードを動的に作成および削除 (さらにはシャード マップ マネージャーを透過的に更新) できます。 ただし、シャードを削除する操作は、そのシャード内のすべてのデータの削除を要求する破壊的な操作です。

アプリケーションで、1 つのシャードを 2 つのシャードに分割する、または複数のシャードを 1 つのシャードにマージする必要がある場合、Elastic Database には、個別の分割マージ サービスが用意されています。 このサービスはクラウドでホストされたサービス内で動作し (開発者が作成する必要があります)、シャード間でデータを安全に移動します。 詳細については、Microsoft Web サイトで「 [Elastic Database 分割/マージ ツールを使用したスケーリング] 」を参照してください。

## <a name="partitioning-strategies-for-azure-storage"></a>Azure Storage 用のパーティション分割戦略
Azure Storage は、データを管理するための 4 つの抽象化概念を提供します。

* Blob Storage は、非構造化オブジェクト データを格納します。 ドキュメント、メディア ファイル、アプリケーション インストーラーなど、任意の種類のテキスト データやバイナリ データを BLOB として保存できます。 Blob Storage は、オブジェクト ストレージとも呼ばれます。
* Table Storage には、構造型データセットが格納されます。 Table Storage は、NoSQL キー属性データ ストアであるため、開発が迅速化され、大量のデータにすばやくアクセスできます。
* Queue Storage は、ワークフロー処理およびクラウド サービスのコンポーネント間通信のための、信頼性の高いメッセージング機能を提供します。
* File Storage は、標準的な SMB プロトコルを使用して、レガシ アプリケーション用の共有ストレージを提供します。 Azure の仮想マシンおよびクラウド サービスでは、マウントされている共有を介して、アプリケーション コンポーネント間でファイル データを共有できます。オンプレミスのアプリケーションでは、ファイル サービス REST API を介して、共有内のファイル データにアクセスできます。

Table Storage と Blob Storage は、本質的にキー値ストアで、それぞれ構造化データおよび非構造化データを保持するように最適化されています。 ストレージ キューは、疎結合で拡張性のあるアプリケーションを構築するメカニズムを提供します。 Table Storage、File Storage、Blob Storage、およびストレージ キューは、Azure ストレージ アカウントのコンテキスト内で作成されます。 ストレージ アカウントは、冗長性に関して 3 つの形態をサポートします。

* **ローカル冗長ストレージ**: 単一のデータセンター内に 3 つのデータ コピーを維持します。 この形態の冗長性は、ハードウェア障害に対して保護を提供しますが、データセンター全体を使用不能にする災害に対しては保護を提供しません。
* **ゾーン冗長ストレージ**: 同じリージョン内 (または地理的に近い 2 つのリージョン間) の異なるデータセンター間で 3 つのデータ コピーを維持します。 この形態の冗長性は、単一のデータセンター内で発生する災害に対して保護を提供できますが、リージョン全体に影響する大規模なネットワーク切断に対しては保護を提供できません。 ゾーン冗長ストレージは、現在、ブロック BLOB に対してのみ利用できることに注意してください。
* **geo 冗長ストレージ**: 6 つのデータ コピーを維持します。3 つのコピーを 1 つのリージョン (ローカル リージョン) に、別の 3 つのコピーをリモート リージョンに維持します。 この形態の冗長性は、災害に対する最高レベルの保護を提供します。

Microsoft は、Azure Storage の拡張性ターゲットを公表しています。 詳細については、Microsoft Web サイトの「 [Azure Storage のスケーラビリティおよびパフォーマンスのターゲット] 」を参照してください。 現在、ストレージ アカウントの総容量は、500 TB を超えることはできません (これには、Table Storage、File Storage、および Blob Storage に保持されているデータのサイズと、ストレージ キューに保持されている未処理のメッセージのサイズが含まれます)。

ストレージ アカウント (1 KB エンティティ、BLOB、またはメッセージのサイズを想定) に対する要求の最大レートは、1 秒あたり 20,000 要求です。 ストレージ アカウントの最大値は、ファイル共有あたり 1000 IOPS (8 KB のサイズ) です。 システムでこれらの制限を超えることが想定される場合は、負荷を複数のストレージ アカウント間でパーティション分割することを検討します。 Azure サブスクリプションあたり、最大 200 ストレージ アカウントを作成できます。 ただし、これらの制限は将来変更される可能性があることに注意してください。

## <a name="partitioning-azure-table-storage"></a>Azure Table Storage のパーティション分割
Azure Table Storage は、パーティション分割に対応するように設計されたキーと値のストアです。 すべてのエンティティは、パーティションに格納され、パーティションは Azure Table Storage によって内部的に管理されます。 テーブルに格納される各エンティティは、次のものを含む 2 つの部分で構成されるキーを提供する必要があります。

* **パーティション キー**。 これは文字列値で、Azure Table Storage がこのエンティティを配置するパーティションを決定するために使用されます。 同じパーティション キーを持つすべてのエンティティは、同じパーティションに格納されます。
* **行キー**。 これは別の文字列値で、パーティション内のエンティティを識別します。 パーティション内のすべてのエンティティは、このキーの昇順で辞書的に並び替えられます。 パーティション キーと行キーの組み合わせは、各エンティティで一意になる必要があり、1 KB の長さを超えることはできません。

エンティティのデータの残りの部分は、アプリケーションで定義されたフィールドで構成されます。 特定のスキーマが強制されることはありません。各行は、異なるセットのアプリケーションで定義されたフィールドを持つことができます。 唯一の制限は、エンティティのパーティション キーと行キーを含む最大サイズで、現在は 1 MB です。 テーブルの最大サイズは 200 TB です。ただし、これらの値は、将来変更される可能性があります。 これらの制限に関する最新の情報については、Microsoft Web サイトの「[Azure Storage のスケーラビリティおよびパフォーマンスのターゲット]」のページを参照してください。

この容量を超えるエンティティを格納する必要がある場合、複数のテーブルに分割することを検討します。 垂直的パーティション分割を使用し、フィールドを最も一緒にアクセスされる頻度の高いグループに分割します。

図 7 に、架空の e コマース アプリケーションのサンプル ストレージ アカウント (Contoso Data) の論理構造を示します。 このストレージ アカウントは、3 つのテーブル (Customer Info、Product Info、および Order Info) を含みます 各テーブルには複数のパーティションがあります。

Customer Info テーブルでは、データは顧客の所在地の市に従ってパーティション分割され、行キーには顧客 ID が含まれます。 Product Info テーブルでは、製品が製品カテゴリによってパーティション分割され、行キーには製品番号が含まれます。 Order Info テーブルでは、注文が注文日によってパーティション分割され、行キーには、注文が受信された時刻が指定されます。 すべてのデータは、各パーティションで行キーの順に並べられることに注意してください。

![サンプル ストレージ アカウントのテーブルとパーティション](./images/data-partitioning/TableStorage.png)

*図 7: サンプル ストレージ アカウントのテーブルとパーティション*

> [!NOTE]
> Azure Table Storage は、各エンティティにタイムスタンプ フィールドも追加します。 タイムスタンプ フィールドは Table Storage により維持され、エンティティが変更されるごとに更新されて、パーティションに書き戻されます。 Table Storage サービスはこのフィールドを使用して、緩やかな同時アクセス制御を実装します(アプリケーションがエンティティを Table Storage に書き戻すごとに、Table Storage サービスは、書き込まれるエンティティのタイムスタンプの値と Table Storage に保持されている値を比較します。 異なる場合は、エンティティの取得後に別のアプリケーションがエンティティを変更していると判断され、書き込み操作は失敗します)。 アプリケーションのコードでこのフィールドを変更しないでください。 また、新しいエンティティを作成するときに、このフィールド用の値を指定しないでください。
>
>

Azure Table Storage は、パーティション キーを使用して、データを格納する方法を決定します。 以前に使用されていないパーティション キーを使用してエンティティがテーブルに追加される場合、Azure Table Storage はこのエンティティ用に新しいパーティションを作成します。 同じパーティション キーを持つ別のエンティティは、同じパーティションに格納されます。

このメカニズムは、自動スケールアウト戦略を効果的に実装します。 各パーティションは、単一パーティションからデータを取得するクエリが高速に実行できるようにするために、Azure データセンターの単一サーバーに格納されます。 ただし、それぞれのパーティションは、複数のサーバー間で分散して格納することができます。 また、単一のサーバーが複数のパーティションをホストすることもできます (これらのパーティションにサイズの制限がある場合)。

Azure Table Storage 用にエンティティを設計する際には、次の点を考慮する必要があります。

* パーティション キーと行キーの値を選択する際には、データがアクセスされる方法に主眼を置く必要があります。 パーティション キーと行キーの組み合わせは、クエリの大半をサポートするように選択する必要があります。 最も効率的にクエリを実行するには、パーティション キーと行キーを指定してデータを取得します。 パーティション キーと行キーの範囲を指定するクエリは、単一のパーティションをスキャンすることによって完了できます。 データは行キーの順序で並んでいるため、このクエリは比較的高速に実行されます。 クエリでスキャンするパーティションが指定されていない場合、パーティション キーは Azure Table Storage にすべてのパーティションでデータをスキャンするよう要求する可能性があります。

  > [!TIP]
  > エンティティにナチュラル キーが含まれている場合、それをパーティション キーとして使用し、空の文字列を行キーとして指定します。 エンティティに 2 つのプロパティで構成される複合キーがある場合、変化の少ない方のプロパティをパーティション キーとして選択し、別のプロパティを行キーとして指定します。 エンティティに 3 つ以上のキー プロパティがある場合、プロパティの連結を使用して、パーティション キーと行キーを指定します。
  >
  >
* パーティション キーおよび行キー以外のフィールドを使用してデータを検索するクエリを定期的に実行する場合、 [インデックス テーブル パターン]を使用することを検討します。
* 単純に増加または減少する数列 ("0001"、"0002"、"0003"、など) を使用してパーティション キーを生成する場合で、各パーティションには少量のデータしか含まれない場合、Azure Table Storage は、これらのパーティションを物理的にグループ化して、同一のサーバーに配置することがあります。 このメカニズムでは、アプリケーションはパーティションの連続した範囲を対象にするクエリ (範囲クエリ) を実行する可能性が最も高く、このようにすることで最適化されると想定します。 ただし、この手法は、新しいエンティティのすべての挿入操作が連続する範囲の 1 つの末尾または別の末尾に集中する可能性があるので、単一サーバー上にホットスポットを発生させる可能性があります。 また、拡張性が損なわれる可能性もあります。 サーバー間で負荷をさらに均等に分散するために、パーティション キーをハッシュ処理して、数列をさらにランダム化することを検討します。
* Azure Table Storage は、同一パーティションに属するエンティティに対するトランザクション操作をサポートします。 これは、アプリケーションが、複数の挿入、更新、削除、置換、またはマージの操作を 1 つのアトミック単位として実行できることを意味します (トランザクションに含まれるエントリが 100 個以下で、要求のペイロードが 4 MB を超えない場合)。 複数のパーティションにまたがる操作はトランザクションとしてはサポートされません。また、「[Data consistency primer (データ整合性入門) (データ整合性入門)]」で説明されている最終的整合性を実装することが必要になることがあります。 Table Storage とトランザクションの詳細については、Microsoft Web サイトの「[Performing Entity Group Transactions] \(エンティティ グループ トランザクションの実行)」のページを参照してください。
* パーティション キーの粒度については、入念に注意を払ってください。以下はその理由です。
  * すべてのエンティティで同じパーティション キーを使用すると、Table Storage サービスにより、1 つのサーバー上に保持される単一の大きなパーティションが作成されます。 これにより、スケールアウトが機能しなくなり、負荷が単一のサーバーに集中します。 結論として、この手法が適しているのは、少量のエンティティを管理するシステムだけです。 ただし、この手法では、すべてのエンティティをエンティティ グループ トランザクションの対象にすることができます。
  * 各エンティティに対して一意のパーティション キーを使用すると、Table Storage サービスにより、エンティティごとに異なるパーティションが作成され、結果として、エンティティのサイズに依存して小さなパーティションが大量に作成される可能性があります。 この手法は、単一パーティション キーの手法よりも拡張性に優れていますが、エンティティ グループ トランザクションは使用できません。 また、複数のエンティティをフェッチするクエリが複数のサーバーからの読み込みを実行する可能性があります。 ただし、アプリケーションが範囲クエリを実行し、単純数列を使用してパーティション キーを生成すると、これらのクエリが最適化される可能性があります。
  * エンティティのサブセット間でパーティション キーを共有すると、関連するエンティティをグループ化して同一のパーティションに格納できます。 関連するエンティティにアクセスする操作は、エンティティ グループ トランザクションを使用して実行でき、一連の関連するエンティティをフェッチするクエリは単一サーバーにアクセスするだけで結果が返される可能性があります。

Azure Table Storage でデータをパーティション分割する方法の詳細については、Microsoft Web サイトの記事「 [Azure Storage テーブルの設計ガイド] 」を参照してください。

## <a name="partitioning-azure-blob-storage"></a>Azure Blob Storage のパーティション分割
Azure Blob Storage を使用すると、大きなバイナリ オブジェクトを保持できます。現時点でのオブジェクトの最大サイズは、ブロック BLOB で 5 TB、ページ BLOB で 1 TB です。 最新の情報については、Microsoft Web サイトの「[Azure Storage のスケーラビリティおよびパフォーマンスのターゲット]」のページを参照してください。大量のデータを高速にアップロードまたはダウンロードする必要があるストリーミングのようなシナリオでは、ブロック BLOB を使用します。 データの一部への順次アクセスではなくランダム アクセスを必要とするアプリケーションでは、ページ BLOB を使用します。

ブロック BLOB とページ BLOB のいずれも、Azure ストレージ アカウントのコンテナーに保持されます。 コンテナーを使用することにより、同じセキュリティ要件を持つ関連する BLOB をグループ化することができます。 このグループ化は、物理的ではなく、論理的です。 コンテナー内では、各 BLOB は一意の名前を持ちます。

BLOB のパーティション キーは、アカウント名とコンテナー名と BLOB 名を組み合わせたものです。 つまり、BLOB への負荷からの要求に応じて、各 BLOB は独自のパーティションを持つことができます。 BLOB は、アクセスをスケールアウトするために多数のサーバーに分散させることができますが、1 つの BLOB を処理できるのは 1 台のサーバーのみです。 

単一のブロック (ブロック BLOB) またはページ (ページ BLOB) を書き込む操作はアトミックですが、複数のブロック、ページ、または BLOB にまたがる操作はアトミックではありません。 複数のブロック、ページ、または BLOB にまたがる書き込み操作の実行中に一貫性を確保するには、BLOB リースを使用して書き込みロックを取得する必要があります。

Azure Blob Storage は、最大 60 MB/秒の転送速度、または各 BLOB に対して最大 500/秒の要求をサポートします。 これらの制限を超えることが予想され、BLOB データが比較的静的である場合、Azure Content Delivery Network を使用して BLOB をレプリケートすることを検討します。 詳細については、Microsoft Web サイトの [Azure Content Delivery Network] に関するページを参照してください。 その他のガイダンスと考慮事項については、[Azure Content Delivery Network の使用]に関する記事を参照してください。

## <a name="partitioning-azure-storage-queues"></a>Azure ストレージ キューのパーティション分割
Azure ストレージ キューを使用すると、プロセス間の非同期メッセージ処理を実装できます。 Azure ストレージ アカウントは任意の数のキューを含むことができ、各キューは任意の数のメッセージを含むことができます。 唯一の制限は、ストレージ アカウントで利用できる領域です。 個々のメッセージの最大サイズは、64 KB です。 このサイズよりも大きいメッセージを必要とする場合は、代わりに Azure Service Bus キューの使用を検討します。

各ストレージ キューは、それを含むストレージ アカウント内で一意の名前を持ちます。 Azure はこの名前に基づいてキューをパーティション分割します。 同じキューのすべてのメッセージは同一のパーティションに格納され、単一のサーバーにより制御されます。 負荷を均等化するために、キューごとに異なるサーバーで管理することができます。 サーバーへのキューの割り当ては、アプリケーションおよびユーザーにとって透過的です。

 大規模なアプリケーションでは、アプリケーションのすべてのインスタンスに対して同一のストレージ キューを使用しないでください。この手法では、キューをホストするサーバーがホットスポットになる可能性があるためです。 代わりに、アプリケーションの機能分野ごとに異なるキューを使用してください。 Azure ストレージ キューはトランザクションをサポートしません。このため、メッセージを別のキューに転送することは、メッセージ処理の一貫性にほとんど影響を与えません。

Azure ストレージ キューは、最大 2,000 メッセージ/秒を処理できます。  これよりも多いメッセージを処理する必要がある場合、複数のキューを作成することを検討します。 たとえば、グローバル アプリケーションで、複数のストレージ アカウントのそれぞれにストレージ キューを作成し、各リージョンで動作するアプリケーション インスタンスを処理します。

## <a name="partitioning-strategies-for-azure-service-bus"></a>Azure Service Bus 用のパーティション分割戦略
Azure Service Bus はメッセージ ブローカーを使用して、Service Bus のキューまたはトピックに送信されるメッセージを処理します。 既定では、キューまたはトピックに送信されるすべてのメッセージは、同一のメッセージ ブローカー プロセスによって処理されます。 このアーキテクチャにより、メッセージ キューの全体的なスループットに制限が生じる可能性があります。 ただし、キューまたはトピックの作成時にそれらをパーティション分割することもできます。 そのためには、キューまたはトピックの *EnablePartitioning* プロパティを *true* に設定します。

パーティション分割されたキューまたはトピックは複数のフラグメントに分割され、それぞれのフラグメントは個別のメッセージ ストアおよびメッセージ ブローカーにより返されます。 これらのフラグメントの作成および管理は、Service Bus によって行われます。 アプリケーションがメッセージをパーティション分割されたキューまたはトピックに送信すると、Service Bus はメッセージをそのキューまたはトピックのフラグメントに割り当てます。 アプリケーションがメッセージをキューまたはサブスクリプションから受信すると、Service Bus は各フラグメントで次に利用可能なメッセージが存在するかどうかを確認し、存在する場合はそのメッセージを処理するために、アプリケーションに渡します。

この構造は、メッセージ ブローカー間およびメッセージ ストア間で負荷を分散するのに役立ち、拡張性と可用性を向上させます。 1 つのフラグメントのメッセージ ブローカーまたはメッセージ ストアが一時的に利用できなくなると、Service Bus は利用可能な残りのフラグメントの 1 つからメッセージを取得できます。

Service Bus は、次の手順に従って、メッセージをフラグメントに割り当てます。

* メッセージがセッションに属する場合、SessionId プロパティと同じ値を持つすべてのメッセージは、同一のフラグメントに送信されます。
* メッセージはセッションに属していないが、送信者が *PartitionKey* プロパティの値を指定している場合、同じ *PartitionKey* 値を持つすべてのメッセージは、同一のフラグメントに送信されます。

  > [!NOTE]
  > *SessionId* および *PartitionKey* プロパティの両方を指定している場合、これらを同じ値に設定する必要があります。そうしないと、メッセージは拒否されます。
  >
  >
* メッセージの *SessionId* プロパティと *PartitionKey* プロパティは指定されていないが、重複検出が有効な場合、*MessageId* プロパティが使用されます。 同じ *MessageId* を持つすべてのメッセージは、同一のフラグメントに転送されます。
* メッセージに *SessionId、PartitionKey*、または *MessageId* のいずれのプロパティも含まれていない場合、Service Bus は順番にメッセージをフラグメントに割り当てます。 あるフラグメントが利用できない場合、Service Bus は次のフラグメントに移動します。 つまり、メッセージ インフラストラクチャで一時的な障害が発生しても、メッセージ送信操作が失敗することはありません。

Service Bus のメッセージのキューまたはトピックをパーティション分割するかどうか、また、パーティション分割する方法を決定するときは、次の点を考慮する必要があります。

* Service Bus のキューとトピックは、Service Bus 名前空間のスコープ内で作成されます。 Service Bus は、現在、名前空間あたり最大 100 のパーティション分割されたキューまたはトピックをサポートします。
* 各 Service Bus 名前空間は利用可能なリソースについてクォータが適用されます。これらのリソースには、トピックあたりのサブスクリプションの数、秒あたりの同時送受信要求の数、確立可能な同時接続の最大数などがあります。 これらのクォータの詳細については、Microsoft Web サイトの [Service Bus のクォータ]に関するページを参照してください。 これらの値を超えることが予想される場合、独自のキューとトピックを持つ追加の名前空間を作成し、負荷をこれらの名前空間間で分散します。 たとえば、グローバル アプリケーションで、リージョンごとに個別の名前空間を作成し、最も近い名前空間のキューとトピックを使用するように、アプリケーション インスタンスを構成します。
* トランザクションの一部として送信されるメッセージでは、パーティション キーを指定する必要があります。 これは、*SessionId*、*PartitionKey*、または *MessageId* プロパティで指定できます。 同一トランザクションの一部として送信されるすべてのメッセージは、同じパーティション キーを指定する必要があります。これは、これらのメッセージが同一のメッセージ ブローカー プロセスによって処理される必要があるためです。 同一トランザクション内のメッセージを異なるキューまたはトピックに送信することはできません。
* パーティション分割されたキューおよびトピックは、アイドル状態になったときに自動的に削除されるように構成することはできません。
* クロスプラットフォームまたはハイブリッドのソリューションを構築している場合、現在、パーティション分割されたキューおよびトピックを Advanced Message Queuing Protocol (AMQP) で使用することはできません。

## <a name="partitioning-strategies-for-cosmos-db"></a>Cosmos DB 用のパーティション分割戦略

Azure Cosmos DB は [Azure Cosmos DB SQL API][cosmosdb-sql-api] を使用して JSON ドキュメントを格納できる NoSQL データベースです。 Cosmos DB データベースのドキュメントは、オブジェクトまたは他の種類のデータの JSON シリアル化された表現です。 すべてのドキュメントは一意な ID を含む必要があることを除いて、いずれの固定されたスキーマも強制されません。

ドキュメントはコレクションに編成されます。 コレクションでは、関連するドキュメントをグループ化できます。 たとえば、ブログ投稿を維持するシステムでは、各ブログ投稿のコンテンツをドキュメントとしてコレクションに格納できます。 また、各サブジェクト タイプのコレクションも作成できます。 また、さまざまな著者が自身のブログ投稿を制御および管理するシステムなどのマルチテナント アプリケーションでは、ブログを著者別にパーティション分割して、著者ごとに個別のコレクションを作成できることがあります。 コレクションに割り当てられるストレージ領域は、弾力性があり、必要に応じて縮小または拡大できます。

Cosmos DB では、アプリケーションで定義されたパーティション キーに基づくデータの自動パーティション分割をサポートします。 "*論理パーティション*" は、1 つのパーティション キー値に対応するすべてのデータを格納するパーティションです。 同じパーティション キー値を共有するすべてのドキュメントは、同じ論理パーティション内に配置されます。 Cosmos DB では、パーティション キーのハッシュに従って値を分散配置します。 論理パーティションの最大サイズは 10 GB です。 したがって、パーティション キーの選択は、設計時の重要な決定事項の 1 つです。 値が多岐にわたっていて、なおかつ均等なアクセス パターンを持つプロパティを選択します。 詳細については、「[Azure Cosmos DB でのパーティション分割とスケーリング](/azure/cosmos-db/partition-data)」を参照してください。

> [!NOTE]
> 各 Cosmos DB データベースには、取得するリソースの量を決定する "*パフォーマンス レベル*" があります。 パフォーマンス レベルには、関連する "*要求ユニット*" (RU) レートの制限があります。 RU レートの制限は、そのコレクションに予約されており、そのコレクションによって排他使用できるリソースの量を指定します。 コレクションのコストは、そのコレクションによって選択されたパフォーマンス レベルに依存します。 パフォーマンス レベル (および RU レートの制限) が高くなるほど、料金も高くなります。 コレクションのパフォーマンス レベルは、Azure Portal を使用することにより調整できます。 詳細については、「[Azure Cosmos DB の要求ユニット][cosmos-db-ru]」を参照してください。
>
>

Cosmos DB が提供するパーティション分割メカニズムでは十分でない場合、アプリケーション レベルでデータをシャード化する必要がある場合があります。 ドキュメント コレクションは、単一データベース内でデータをパーティション分割するための自然なメカニズムを提供します。 シャーディングを実装するための最も簡単な方法は、各シャード用にコレクションを作成することです。 コンテナーは論理リソースであり、1 つ以上のサーバーにまたがることができます。 固定サイズのコンテナーの上限は、容量が 10 GB で、スループットが毎秒 10,000 RU となります。 無制限のコンテナーには最大ストレージ サイズはありませんが、パーティション キーを指定する必要があります。 クライアント アプリケーションは、アプリケーション シャーディングを使用して要求を適切なシャードに転送する必要があります。このためには、通常、シャード キーを定義するデータのいくつかの属性に基づいて、独自のマッピング メカニズムを実装します。 

すべてのデータベースは、Cosmos DB アカウントのコンテキストで作成されます。 1 つのアカウントに複数のデータベースを含めることができ、アカウントによりデータベースの作成先となるリージョンが指定されます。 また、各アカウントは、独自のアクセス制御を実行します。 Cosmos DB アカウントを使用して、シャード (データベース内のコレクション) をそれらにアクセスする必要のあるユーザーの近くに geo 配置し、それらのユーザーだけがそれらのシャードに接続できるように制限を強制することができます。

Cosmos DB SQL API でデータをパーティション分割する方法を決定する際には、次の点を考慮する必要があります。

* **Cosmos DB データベースで利用できるリソースは、アカウントのクォータ制限の対象になります**。 各データベースは複数のコレクションを保持できます。各コレクションには、そのコレクションの RU レートの制限 (予約されているスループット) を管理するパフォーマンス レベルが関連付けられています。 詳細については、「[Azure サブスクリプションとサービスの制限、クォータ、制約][azure-limits]」をご覧ください。
* **各ドキュメントには、それが保持されるコレクション内でそれを一意に識別するために使用できる属性が存在する必要があります**。 この属性は、ドキュメントの保持先となるコレクションを定義するシャード キーとは異なります。 コレクションは大量のドキュメントを含むことができます。 理論的には、ドキュメント ID の最大長によってのみ制限されます。 ドキュメント ID の最大長は、255 文字です。
* **ドキュメントに対するすべての操作は、トランザクションのコンテキスト内で実行されます。トランザクションは、ドキュメントが含まれているコレクションに対象が制限されます。** 操作が失敗すると、それまでに実行された作業はロールバックされます。 ドキュメントは操作の対象ですが、実行されるすべての変更は、スナップショット レベルで分離されます。 このメカニズムは、たとえば、新しいドキュメントを作成する要求が失敗すると、同時にデータベースをクエリしている別のユーザーが、その時点で削除された不完全なドキュメントを見ることはないことを保証します。
* **データベース クエリもまた、コレクション レベルの範囲に制限されます**。 単一のクエリは、1 つのコレクションのみからのデータを取得できます。 複数のコレクションからデータを取得する必要がある場合、各コレクションを個別にクエリし、結果をアプリケーション コードでマージする必要があります。
* **Cosmos DB はプログラム可能な項目をサポートします。これらはすべて、ドキュメントと一緒にコレクションに格納できます**。 このような項目としては、ストアド プロシージャ、ユーザー定義の関数、および JavaScript で記述されたトリガーがあります。 これらの項目は、同一コレクション内の任意のドキュメントにアクセスできます。 さらに、これらの項目は、ドキュメントに対して実行された作成、削除、または置換の操作の結果として起動されるトリガーの場合には、アンビエント トランザクションのスコープ内で実行します。また、明示的なクライアント要求の結果として実行されるストアド プロシージャの場合には、新しいトランザクションを開始することによって実行されます。 プログラム可能な項目内のコードが例外をスローすると、トランザクションはロールバックされます。 ストアド プロシージャとトリガーを使用してドキュメント間の整合性と一貫性を維持できますが、これらのドキュメントはすべて、同一のコレクション内に含まれている必要があります。
* **データベースに保持することが想定されているコレクションが、コレクションのパフォーマンス レベルによって定義されているスループット制限を超えないことを確認する必要があります**。 詳細については、「[Azure Cosmos DB の要求ユニット][cosmos-db-ru]」を参照してください。 これらの制限に到達することが予想される場合は、異なるアカウントのデータベースにまたがってコレクションを分割して、コレクションあたりの負荷を軽減します。

## <a name="partitioning-strategies-for-azure-search"></a>Azure Search 用のパーティション分割戦略
データを検索する機能は、多くの Web アプリケーションによって提供されるナビゲーションと探索の主要な方法です。 ユーザーは、検索条件の組み合わせに基づいて、リソース (たとえば、e コマース アプリケーションでの製品) をすばやく見つけることができます。 Azure Search サービスは、Web コンテンツに対するフルテキスト検索機能に加えて、先行入力、近似一致に基づくクエリ候補表示、ファセット ナビゲーションなどの機能を提供しています。 これらの機能の詳細については、Microsoft Web サイトの「[Azure Search とは]」を参照してください。

Azure Search は、検索可能なコンテンツを JSON ドキュメントとしてデータベースに格納します。 これらのドキュメントの検索可能なフィールドを指定するインデックスを定義し、これらの定義を Azure Search に提供します。 ユーザーが検索要求を発行すると、Azure Search は適切なインデックスを使用して一致する項目を検索します。

競合を少なくするために、Azure Search によって使用されるストレージは、最大 1、2、3、4、6、または 12 のパーティションに分割でき、各パーティションは最大 6 回レプリケートできます。 パーティションの数とレプリカの数の積は、"*検索単位*" (SU) と呼ばれます。 Azure Search の単一インスタンスは、最大 36 SU を含むことができます (12 のパーティションを持つデータベースは、最大 3 つのレプリカをサポートします)。

課金は、サービスに割り当てられている各 SU に対して行われます。 検索可能なコンテンツの量、または検索要求の割合が増加した場合、Azure Search の既存のインスタンスに SU を追加して、増加した負荷を処理できます。 Azure Search 自体が、パーティション間にドキュメントを均等に分散します。 手動によるパーティション分割戦略は、現時点でサポートされていません。

各パーティションは、最大 1,500 万のドキュメント、または 300 GB のストレージ領域のいずれか少ない方を収容できます。 最大 50 のインデックスを作成できます。 サービスのパフォーマンスは、ドキュメントの複雑さ、利用可能なインデックス、およびネットワーク遅延の影響によって異なります。 平均すると、単一レプリカ (1 SU) は 15 クエリ/秒 (QPS) を処理できます。ただし、スループットをより正確に測定するために、自身のデータを使用してベンチマークを実行することをお勧めします。 詳細については、Microsoft Web サイトの「[Azure Search サービスの制限]」を参照してください。

> [!NOTE]
> 検索可能ドキュメントには、限定されたセットのデータ型を格納できます。これらのデータには、文字列、ブール値、数値データ、日付時刻データ、および一部の地理的データが含まれます。 詳細については、Microsoft Web サイトの「[Supported data types (Azure Search) (サポートされるデータ型 (Azure Search))]」を参照してください。
>
>

Azure Search がサービスの各インスタンス用にデータをパーティション分割する方法については、限定された制御しかできません。 ただし、グローバル環境では、次のいずれかの戦略を使用してサービス自体をパーティション分割することにより、パフォーマンスを向上させ、遅延を小さくし、競合を少なくすることができる場合があります。

* 各リージョンで Azure Search のインスタンスを作成し、クライアント アプリケーションの要求が最も近い利用可能なインスタンスに転送されることを確認します。 この戦略では、検索可能なコンテンツに対するすべての更新がサービスのすべてのインスタンスに対して、遅れることなくレプリケートされる必要があります。
* Azure Search の 2 つの階層を作成します。

  * 各リージョンに、そのリージョンで最も頻繁にアクセスされるデータを含むローカル サービス。 限定的な結果でも早くほしい場合は、ここに要求できます。
  * すべてのデータを収容するグローバル サービス。 時間がかかっても完全な結果が必要な場合は、ここに要求できます。

この手法は、検索対象のデータに大きな地域的な相違がある場合に最も適しています。

## <a name="partitioning-strategies-for-azure-redis-cache"></a>Azure Redis Cache 用のパーティション分割戦略
Azure Redis Cache は、Redis キー/値データ ストアに基づく、クラウド内の共有キャッシュ サービスを提供します。 名前が示すように、Azure Redis Cache はキャッシュ ソリューションを意図しています。 恒久的なデータ ストアとしてではなく、一時的なデータを保持するためにのみ使用する必要があります。 Azure Redis Cache を利用するアプリケーションは、キャッシュが利用できない場合でも、継続して動作できる必要があります。 Azure Redis Cache はプライマリ/セカンダリ レプリケーションをサポートし、高可用性を提供しますが、現在、最大キャッシュ サイズは 53 GB に制限されています。 このサイズを超える領域を必要とする場合は、追加のキャッシュを作成する必要があります。 詳細については、Microsoft Web サイトの「 [Azure Redis Cache] 」を参照してください。

Redis データ ストアをパーティション分割する場合、Redis サービスのインスタンス全体でデータを分割します。 各インスタンスは、単一パーティションを構成します。 Azure Redis Cache はファサードの背後に Redis サービスを抽象化し、それらが直接アクセスされないようにします。 パーティション分割を実装する最も簡単な方法は、複数の Azure Redis Cache インスタンスを作成し、データをそれら全体に分散することです。

データ項目の格納先となるキャッシュを指定する識別子 (パーティション キー) と各データ項目を関連付けることができます。 クライアント アプリケーション ロジックはこの識別子を使用して、要求を適切なパーティションにルーティングできます。 この構成は非常に単純ですが、パーティション分割構成が変更されると (たとえば、追加の Azure Redis Cache インスタンスが作成されると)、クライアント アプリケーションの再構成が必要になる場合があります。

Azure Redis Cache ではないネイティブ Redis は、Redis クラスタリングに基づくサーバー側のパーティション分割をサポートします。 この手法では、ハッシュ メカニズムを使用することにより、データをサーバー間で均等に分散できます。 各 Redis サーバーは、パーティションが保持するハッシュ キーの範囲を定義するメタデータを格納します。また、他のサーバーのパーティションに配置されているハッシュ キーに関する情報も含みます。

クライアント アプリケーションは単純に要求を、パーティション分割された任意の Redis サーバー (最も近いサーバーの可能性大) に送信します。 Redis サーバーは、クライアント要求を調べます。 ローカルで解決できる場合、要求された操作が実行されます。 ローカルで解決できない場合、適切なサーバーに要求が転送されます。

このモデルは Redis クラスタリングを使用することによって実装されます。詳細については、Redis Web サイトの「[Redis cluster tutorial (Redis クラスターのチュートリアル)]」ページを参照してください。 Redis クラスタリングはクライアント アプリケーションにとって透過的なものです。 クライアントを再構成しなくても追加の Redis サーバーをクラスターに追加できます (およびデータを再パーティション分割できます)。

> [!IMPORTANT]
> 現在、Azure Redis Cache と Redis クラスタリングは併用できません。 Azure でこの手法を実装したい場合は、一連の Azure Virtual Machines に Redis をインストールし、手動で構成することにより、独自の Redis サーバーを実装する必要があります。 Microsoft Web サイトの「 [Running Redis on a CentOS Linux VM in Microsoft Azure (Microsoft Azure の CentOS Linux VM 上での Redis の実行)] 」のページでは、Azure VM として実行される Redis ノードの構築および設定方法を示す例について説明しています。
>
>

Redis Web サイトの「 [Partitioning: how to split data among multiple Redis instances (パーティション分割: 複数の Redis インスタンス間でデータを分割する方法) (パーティション分割: 複数の Redis インスタンス間でデータを分割する方法)] 」には、Redis へのパーティション分割の実装に関する詳細情報が記載されています。 このセクションの以降の説明では、クライアント側またはプロキシに支援されたパーティション分割を実装していると想定します。

Azure Redis Cache でデータをパーティション分割する方法を決定する際には、次の点を検討する必要があります。

* Azure Redis Cache は恒久的なデータ ストアとして動作するようには意図されていません。このため、実装するパーティション分割構成に関係なく、アプリケーション コードはキャッシュではない場所からデータを取得できる必要があります。
* 頻繁に一緒にアクセスされるデータは、同一パーティションに維持する必要があります。 Redis は強力なキー値ストアで、データを構造化するための高度に最適化された一連のメカニズムを提供します。 次のようなメカニズムがあります。

  * 単純な文字列 (最大 512 MB の長さバイナリ データ)
  * リストなどの集約型 (キューおよびスタックとして動作可能)
  * セット (順序ありおよび順序なし)
  * ハッシュ (オブジェクト内のフィールドを表す項目などの関連するフィールドをグループ化することが可能)
* 集約型を使用すると、多くの関連する値を同じキーに関連付けることができます。 Redis キーは、それが含むデータ項目ではなく、リスト、セット、またはハッシュを識別します。 これらの型は、Azure Redis Cache ですべて利用できます。詳細については、Redis Web サイトの「[Data Types (データ型)]」を参照してください。 たとえば、顧客により登録された注文を追跡する e コマース システムの一部として、各顧客の詳細情報を、顧客 ID をキーとして使用して Redis ハッシュに格納できる場合があります。 各ハッシュは、その顧客の注文 ID のコレクションを保持することができます。 別の Redis セットで注文を保持することもできます。この場合も、ハッシュとして構造化され、注文 ID をキーとして使用します。 図 8 に、この構造を示します。 Redis では、いずれの形態の参照整合性も実装しないので、開発者は、顧客と注文の間の関係を維持するロジックを組み込む必要があります。

![顧客の注文とそれらの詳細情報を記録するために Redis ストレージで想定される構造](./images/data-partitioning/RedisCustomersandOrders.png)

*図 8: 顧客の注文とそれらの詳細情報を記録するために Redis ストレージで想定される構造*

> [!NOTE]
> Redis では、すべてのキーは、Redis 文字列と同じようなバイナリ データ値で、最大で 512 MB のデータを含むことができます。 理論的には、キーはあらゆる情報を含むことができます。 ただし、キーに対して一貫した名前付け規則を適用し、データの型をわかりやすく表し、エンティティを識別し、しかも過度に長すぎないような名前を割り当てることをお勧めします。 一般的な方法では、"entity_type:ID" の形のキーを使用します。 たとえば、"customer:99" は ID 99 の顧客のキーを示します。
>
>

* 関連する情報を同一データベースの異なる集約型に格納することによって、垂直的パーティション分割を実装できます。 たとえば、e コマース アプリケーションで、製品について共通してアクセスされる情報を 1 つの Redis ハッシュに格納し、アクセス頻度の低い詳細情報を別の Redis ハッシュに格納できることがあります。
  両方のハッシュはキーの一部として同じ製品 ID を使用できます。 たとえば、製品情報用の "product: *nn*" (*nn* は製品 ID) や詳細データ用の "product_details: *nn*" を使用できます。 この戦略は、ほとんどのクエリが取得する可能性が高いデータの量を少なくするのに役立てることができます。
* Redis データ ストアを再パーティションできますが、複雑で時間のかかる作業であることに留意してください。 Redis クラスタリングではデータの再パーティション分割を自動的に実行できますが、この機能は、Azure Redis Cache とは併用できません。 このため、パーティション分割構成を設計する際には、各パーティションに十分な空き領域を確保して、予想される将来のデータ増加に最初から備える必要があります。 ただし、Azure Redis Cache はデータを一時的にキャッシュすることを意図しており、キャッシュに保持されるデータは有効期間 (TTL) 値として指定される期間だけ有効であることに注意する必要があります。 揮発性が比較的高いデータでは TTL を短くできますが、静的なデータでは、TTL を非常に長くすることができます。 有効期間の長いデータをキャッシュに大量に格納しないでください。そのデータにより、キャッシュがいっぱいになる可能性があります。 強制退去ポリシーを指定して、利用できる領域が少ない場合に Azure Redis Cache がデータを削除できるようにすることができます。

  > [!NOTE]
  > Azure Redis Cache を使用する場合は、適切な価格レベルを選択することにより、キャッシュの最大サイズを 250 MB から 53 GB の範囲で指定します。 ただし、いったん Azure Redis Cache を作成したら、その後にはサイズを大きくしたり小さくしたりすることはできません。
  >
  >
* Redis のバッチおよびトランザクションは、複数の接続を利用できないので、バッチまたはトランザクションによりアクセスされるすべてのデータは同一のデータベース (シャード) で保持する必要があります。

  > [!NOTE]
  > Redis トランザクションの一連の操作は、必ずしもアトミックである必要はありません。 トランザクションを構成するコマンドは、実行前に検証されてキューに登録されます。 この段階でエラーが発生すると、キュー全体が破棄されます。 ただし、トランザクションが正常に発行されると、キューに登録されていた一連のコマンドが正しい順序で実行されます。 いずれかのコマンドで障害が発生すると、そのコマンドの実行だけが中止されます。 キュー内の前後にあるコマンドはすべて実行されます。 詳細については、Redis Web サイトの「 [Transactions (トランザクション)] 」を参照してください。
  >
  >
* Redis は、限定された数のアトミック操作をサポートします。 複数のキーと値をサポートするこの種の操作は、MGET 操作と MSET 操作だけです。 MGET 操作は指定したキー リストの値のコレクションを返し、MSET 操作は指定したキー リストの値のコレクションを格納します。 これらの操作を使用する必要がある場合、MSET コマンドと MGET コマンドによって参照されるキー値ペアは、同一のデータベースに格納される必要があります。

## <a name="partitioning-strategies-for-azure-service-fabric"></a>Azure Service Fabric のためのパーティション分割戦略
Azure Service Fabric は、クラウドの分散アプリケーションにランタイムを提供する microservices プラットフォームです。 Service Fabric は、.Net ゲストの実行可能ファイル、ステートフルおよびステートレスなサービス、およびコンテナーをサポートしています。 ステートフルなサービスは、Service Fabric クラスター内のキー値コレクションにデータを永続的に格納する[信頼性の高いコレクション][service-fabric-reliable-collections]を提供します。 信頼性の高いコレクション内のパーティション分割キー戦略の詳細については、[Azure Service Fabric の Reliable Collections のガイドラインと推奨事項]を参照してください。

### <a name="more-information"></a>詳細情報
* [Azure Service Fabric の概要]は、Azure Service Fabric の導入です。
* [Service Fabric Reliable Services のパーティション分割]では、Azure Service Fabric で信頼性の高いサービスについて詳しく説明しています。

## <a name="partitioning-strategies-for-azure-event-hubs"></a>Azure Event Hubs のためのパーティション分割戦略

[Azure Event Hubs][event-hubs] は、大規模なデータ ストリーミングのために設計されており、パーティション分割は、水平方向のスケーリングを可能にするためにサービスに組み込まれています。 各コンシューマーは、メッセージ ストリームの特定のパーティションのみを読み取ります。 

イベント発行元は、そのパーティション キーのみを認識し、イベントの発行先となるパーティションは認識しません。 このようにキーとパーティションを分離することにより、送信者はダウンストリーム処理について余分な情報を把握しなくてもよくなります。 (特定のパーティションにイベントを直接送信することも可能ですが、通常は推奨されません)。  

パーティション数を選択する場合は、長期間にわたる拡張を考慮してください。 Event hub を作成した後は、パーティションの数を変更できません。 

Event Hubs でのパーティションの使用の詳細については、「[Event Hubs とは]」を参照してください。

可用性と一貫性の間のトレードオフに関する詳細については、「[Event Hubs における可用性と一貫性]」を参照してください。

## <a name="rebalancing-partitions"></a>パーティションの再調整
システムが安定し、使用パターンについての理解が深まると、パーティション分割構成の調整が必要になることがあります。 たとえば、パーティション間でトラフィック量に不均衡が生じ、特定のパーティションがホットスポットになり、過度な競合が発生しているために起きることがあります。 また、一部のパーティションでデータ量が過少に見積もられており、これらのパーティションでストレージ容量の制限に近づいていることもあります。 原因が何であるかに関係なく、パーティションを再調整して、負荷をより均等に分散することが必要になることがあります。

状況によっては、データをサーバーに透過的に割り当てているデータ ストレージ システムは、利用可能なリソースの制限内でパーティションを自動的に再調整できます。 その他の状況では、再調整は、次の 2 段階で構成される管理タスクとなります。

1. 新しいパーティション分割戦略を決定します。
   * 分割またはマージすることが必要なパーティション。
   * 新しいパーティション キーを設計してこれらの新しいパーティションにデータを割り当てる方法。
2. 影響を受けるデータを古いパーティション分割構成から一連の新しいパーティションに移行します。

> [!NOTE]
> Cosmos DB データベース コレクションからサーバーへのマッピングは透過的に行われますが、それでも、Cosmos DB アカウントのストレージ容量とスループットの上限に達する可能性があります。 その場合、パーティション分割構成を再設計し、データを移行することが必要になることがあります。
>
>

データ ストレージのテクノロジとデータ ストレージ システムの設計によっては、パーティションが使用されている間に、データをパーティション間で移行できることがあります (オンライン移行)。 これが不可能な場合、データを再配置する間、影響を受けるパーティションを一時的に利用できないようにすることが必要になることがあります (オフライン移行)。

## <a name="offline-migration"></a>オフライン移行
オフライン移行は、競合が発生する機会を少なくするので、ほぼ間違いなく、最も簡単な手法です。 データは、移動および再構成時に変更されることはありません。

概念的に、このプロセスには次の手順が含まれます。

1. シャードをオフラインにします。
2. データを分割マージして、新しいシャードに移動します。
3. データを検証します。
4. 新しいシャードをオンラインにします。
5. 古いシャードを削除します。

データを部分的に利用できるようにするために、手順 1 で元のシャードを利用不能にする代わりに、読み取り専用にすることもできます。 これにより、データが移動されている間、アプリケーションはデータを読み込むことができます。ただし、変更することはできません。

## <a name="online-migration"></a>オンライン移行
オンライン移行は、実行するのにより複雑な操作を必要としますが、手順全体を通してデータが利用できるので、ユーザーにとってはサービスの中断がより少なくなります。 プロセスは、オフライン移行で使用されるものと類似していますが、元のシャードがオフラインになることはありません (手順 1.)。 移行プロセスの粒度 (たとえば、項目単位に行われるか、またはシャード単位か) に応じて、クライアント アプリケーションのデータ アクセス コードは、2 つの場所 (元のシャードと新しいシャード) に対してデータの読み書きを処理することが必要になる場合があります。

オンライン移行をサポートするソリューションの例については、Microsoft Web サイトの「 [Elastic Database 分割/マージ ツールを使用したスケーリング] 」を参照してください。

## <a name="related-patterns-and-guidance"></a>関連のあるパターンとガイダンス
データの一貫性を実装するための戦略を検討するときは、次のパターンもシナリオに関連する可能性があります。

* Microsoft Web サイトの「[Data consistency primer (データ整合性入門) (データ整合性入門)]」のページでは、クラウドなどの分散環境で一貫性を維持するための戦略が説明されています。
* Microsoft Web サイトの「[Data Partitioning Guidance]」 \(データ パーティション分割ガイダンス)のページでは、分散ソリューションのさまざまな条件を満たすためにパーティションを設計する作業の全般的な概要が説明されています。
* Microsoft Web サイトの「[Sharding Pattern (シャーディング パターン)]」では、データをシャーディングするための一般的な戦略の概要が説明されています。
* Microsoft Web サイトの「[インデックス テーブル パターン]」では、データに対してセカンダリ インデックスを作成する方法が説明されています。 この手法を使用すると、アプリケーションは、コレクションのプライマリ キーを参照しないクエリで、データをすばやく取得できます。
* Microsoft Web サイトの「[Materialized View Pattern] \(具体化されたビュー パターン)」では、高速なクエリ操作をサポートするために、データを要約し、かつデータが事前に取り込まれているビューを生成する方法が説明されています。 この手法は、要約対象のデータを含むパーティションが複数のサイトにまたがって分散されている場合に、パーティション分割されたデータ ストアで役立つ可能性があります。
* Microsoft Web サイトの [Azure Content Delivery Network の使用] に関する記事では、Azure で Content Delivery Network を構成および使用するための詳細なガイダンスが提供されています。

## <a name="more-information"></a>詳細情報
* Microsoft Web サイトの「[SQL Database とは SQL Database の概要、技術の詳細、DTU の説明]」のページでは、SQL データベースを作成および使用する方法が詳細に説明されています。
* Microsoft Web サイトの「[Elastic Database 機能の概要]」ページでは、Elastic Database が包括的に説明されています。
* Microsoft Web サイトの「[Elastic Database 分割/マージ ツールを使用したスケーリング]」のページでは、Split/Merge サービスを使用して Elastic Database シャードを管理する方法が説明されています。
* Microsoft Web サイトの「[Azure Storage のスケーラビリティおよびパフォーマンスのターゲット](https://msdn.microsoft.com/library/azure/dn249410.aspx)」ページでは、Azure Storage のサイズとスループットに関する現在の制限が説明されています。
* Microsoft Web サイトの「[Performing Entity Group Transactions]」 \(エンティティ グループ トランザクションの実行)ページでは、Azure Table Storage に格納されているエンティティを対象にするトランザクション操作を実装する方法が、詳細に説明されています。
* Microsoft Web サイトの「[Azure Storage テーブルの設計ガイド]」の記事では、Azure Table Storage でデータをパーティション分割する方法が詳細に説明されています。
* Microsoft Web サイトの [Azure Content Delivery Network の使用] に関するページでは、Azure Content Delivery Network を使用して、Azure Blob Storage に保持されているデータをレプリケートする方法が説明されています。
* Microsoft Web サイトの「[Azure Search とは]」ページでは、Azure Search で利用できる機能が詳細に説明されています。
* Microsoft Web サイトの「[Azure Search サービスの制限]」のページでは、Azure Search の各インスタンスの容量が説明されています。
* Microsoft Web サイトの「[Supported data types (Azure Search) (サポートされるデータ型 (Azure Search))]」のページでは、検索可能ドキュメントおよびインデックスとして使用可能なデータ型の概要が説明されています。
* Microsoft Web サイトの「[Azure Redis Cache]」のページでは、Azure Redis Cache の概要が説明されています。
* Redis Web サイトの「[Partitioning: how to split data among multiple Redis instances (パーティション分割: 複数の Redis インスタンス間でデータを分割する方法) (パーティション分割: 複数の Redis インスタンス間でデータを分割する方法)]」のページでは、Redis でパーティション分割を実装する方法が説明されています。
* Microsoft Web サイトの「[Running Redis on a CentOS Linux VM in Microsoft Azure (Microsoft Azure の CentOS Linux VM 上での Redis の実行)]」のページでは、Azure VM として実行される Redis ノードの構築および設定方法を示す例について説明しています。
* Redis Web サイトの「[Data Types (データ型)]」のページでは、Redis および Azure Redis Cache で利用可能なデータ型が説明されています。

[Event Hubs における可用性と一貫性]: /azure/event-hubs/event-hubs-availability-and-consistency
[azure-limits]: /azure/azure-subscription-service-limits
[Azure Content Delivery Network]: /azure/cdn/cdn-overview
[Azure Redis Cache]: http://azure.microsoft.com/services/cache/
[Azure Storage のスケーラビリティおよびパフォーマンスのターゲット]: /azure/storage/storage-scalability-targets
[Azure Storage テーブルの設計ガイド]: /azure/storage/storage-table-design-guide
[Building a Polyglot Solution (多言語ソリューションの構築)]: https://msdn.microsoft.com/library/dn313279.aspx
[cosmos-db-ru]: /azure/cosmos-db/request-units
[Data Access for Highly-Scalable Solutions: Using SQL, NoSQL, and Polyglot Persistence (拡張性の高いソリューション用のデータ アクセス: SQL、NoSQL、および Polyglot の永続化機能の使用)]: https://msdn.microsoft.com/library/dn271399.aspx
[Data consistency primer (データ整合性入門) (データ整合性入門)]: http://aka.ms/Data-Consistency-Primer
[Data Partitioning Guidance]: https://msdn.microsoft.com/library/dn589795.aspx
[Data Types (データ型)]: http://redis.io/topics/data-types
[cosmosdb-sql-api]: /azure/cosmos-db/sql-api-introduction
[Elastic Database 機能の概要]: /azure/sql-database/sql-database-elastic-scale-introduction
[event-hubs]: /azure/event-hubs
[Federations Migration Utility]: https://code.msdn.microsoft.com/vstudio/Federations-Migration-ce61e9c1
[Azure Service Fabric の Reliable Collections のガイドラインと推奨事項]: /azure/service-fabric/service-fabric-reliable-services-reliable-collections-guidelines
[インデックス テーブル パターン]: http://aka.ms/Index-Table-Pattern
[Materialized View Pattern]: http://aka.ms/Materialized-View-Pattern
[マルチシャード クエリ実行]: /azure/sql-database/sql-database-elastic-scale-multishard-querying
[Azure Service Fabric の概要]: /azure/service-fabric/service-fabric-overview
[Service Fabric Reliable Services のパーティション分割]: /azure/service-fabric/service-fabric-concepts-partitioning
[Partitioning: how to split data among multiple Redis instances (パーティション分割: 複数の Redis インスタンス間でデータを分割する方法) (パーティション分割: 複数の Redis インスタンス間でデータを分割する方法)]: http://redis.io/topics/partitioning
[Performing Entity Group Transactions]: https://msdn.microsoft.com/library/azure/dd894038.aspx
[Redis cluster tutorial (Redis クラスターのチュートリアル)]: http://redis.io/topics/cluster-tutorial
[Running Redis on a CentOS Linux VM in Microsoft Azure (Microsoft Azure の CentOS Linux VM 上での Redis の実行)]: http://blogs.msdn.com/b/tconte/archive/2012/06/08/running-redis-on-a-centos-linux-vm-in-windows-azure.aspx
[Elastic Database 分割/マージ ツールを使用したスケーリング]: /azure/sql-database/sql-database-elastic-scale-overview-split-and-merge
[Azure Content Delivery Network の使用]: /azure/cdn/cdn-create-new-endpoint
[Service Bus のクォータ]: /azure/service-bus-messaging/service-bus-quotas
[service-fabric-reliable-collections]: /azure/service-fabric/service-fabric-reliable-services-reliable-collections
[Azure Search サービスの制限]:  /azure/search/search-limits-quotas-capacity
[Sharding Pattern (シャーディング パターン)]: http://aka.ms/Sharding-Pattern
[Supported data types (Azure Search) (サポートされるデータ型 (Azure Search))]:  https://msdn.microsoft.com/library/azure/dn798938.aspx
[Transactions (トランザクション)]: http://redis.io/topics/transactions
[Event Hubs とは]: /azure/event-hubs/event-hubs-what-is-event-hubs
[Azure Search とは]: /azure/search/search-what-is-azure-search
[SQL Database とは SQL Database の概要、技術の詳細、DTU の説明]: /azure/sql-database/sql-database-technical-overview
